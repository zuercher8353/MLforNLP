{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Task\n",
    "In this task, you would require to claasify the BBC News text into 5 classes ['business' 'entertainment' 'politics' 'sport''tech'] For this task, the code skeleton has been given and you have to write your code in the #TODO part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing relevant libraries \n",
    "If any of the below list libraries is not installed already, then use \"pip install #library_name\" to install it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.6.0 in /Users/ankushpanwar/opt/anaconda3/lib/python3.8/site-packages (1.6.0)\r\n",
      "Requirement already satisfied: future in /Users/ankushpanwar/opt/anaconda3/lib/python3.8/site-packages (from torch==1.6.0) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /Users/ankushpanwar/opt/anaconda3/lib/python3.8/site-packages (from torch==1.6.0) (1.18.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing BBC News Dataset\n",
    "Source data from public data set on BBC news articles:\n",
    "D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006. [PDF] [BibTeX].\n",
    "\n",
    "http://mlg.ucd.ie/datasets/bbc.html\n",
    "\n",
    "Cleaned up version of the Dataset is given as csv file with the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"bbc-text_train.csv\")\n",
    "data_test= pd.read_csv(\"bbc-text_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>farrell due to make us tv debut actor colin fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>china continues rapid growth china s economy h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>ebbers  aware  of worldcom fraud former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>school tribute for tv host carson more than 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>broadband fuels online expression fast web acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0  entertainment  farrell due to make us tv debut actor colin fa...\n",
       "1       business  china continues rapid growth china s economy h...\n",
       "2       business  ebbers  aware  of worldcom fraud former worldc...\n",
       "3  entertainment  school tribute for tv host carson more than 1 ...\n",
       "4           tech  broadband fuels online expression fast web acc..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            413\n",
       "business         409\n",
       "politics         334\n",
       "tech             319\n",
       "entertainment    305\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training data into Train and validation set\n",
    "Note: Validation set is surrogate to test set and while training the network , we evaluate the model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_df,val_x_df,train_y_df,val_y_df = train_test_split(data_train['text'],data_train['category'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding prediction classes/labels into integers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business' 'entertainment' 'politics' 'sport' 'tech']\n"
     ]
    }
   ],
   "source": [
    "le =LabelEncoder()\n",
    "le.fit(train_y_df)\n",
    "print(le.classes_)\n",
    "train_y=le.transform(train_y_df)\n",
    "val_y=le.transform(val_y_df)\n",
    "test_y=le.transform(data_test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting News text into numerical vector using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b18ac221fe8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(train_x_df)\n",
    "train_x=vectorizer.transform(train_x_df)\n",
    "val_x=vectorizer.transform(val_x_df)\n",
    "test_x=vectorizer.transform(data_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-583a2564af36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "train_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e491eb782bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mClassificationNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassificationNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         '''\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class ClassificationNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        '''\n",
    "        Defining layers of neural network\n",
    "        '''\n",
    "        self.fc1 = nn.Linear(24295, 64) \n",
    "        self.fc2 = nn.Linear(64, 5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (data_points, num_features)\n",
    "        Returns:\n",
    "            the resulting tensor.\n",
    "        \"\"\"\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net =ClassificationNet()\n",
    "\n",
    "#define learning rate\n",
    "learning_rt=0.5\n",
    "\n",
    "#Construct an optimizer object\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rt)\n",
    "\n",
    "#Construct an loss/criterion object\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "#define number of epochs/ number of training iteration\n",
    "epochs=300\n",
    "\n",
    "#converting train and validation set arrays to tensor\n",
    "train_x_tensor=torch.tensor(train_x.toarray()).float()\n",
    "train_y_tensor=torch.tensor(train_y)\n",
    "val_x_tensor=torch.tensor(val_x.toarray()).float()\n",
    "val_y_tensor=torch.tensor(val_y)\n",
    "\n",
    "\n",
    "def evaluation_metrics(predict_y,ground_truth_y):\n",
    "    '''\n",
    "    Returns accuracy and f1 score metrics for evaluation\n",
    "    '''\n",
    "    accuracy=accuracy_score(ground_truth_y,predict_y)\n",
    "    f1score=f1_score(ground_truth_y,predict_y,average='macro')\n",
    "    \n",
    "    return (accuracy,f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f69cf53f175f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# the training routine is these 5 steps:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# step 1. zero the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # the training routine is these 5 steps:\n",
    "    \n",
    "    # step 1. zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # step 2. compute the output\n",
    "    output = net(train_x_tensor)\n",
    "    \n",
    "    # step 3. compute the loss\n",
    "    loss = criterion(output, train_y_tensor)\n",
    "    \n",
    "    # step 4. use loss to produce gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # step 5. use optimizer to take gradient step\n",
    "    optimizer.step() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # validation set evaluation:\n",
    "        \n",
    "        # compute the output\n",
    "        output_val=net(val_x_tensor)\n",
    "        \n",
    "        # compute the loss\n",
    "        loss_val = criterion(output_val, val_y_tensor)\n",
    "        \n",
    "        # compute the prediction\n",
    "        predict_y= output_val.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # Use the \"evaluation_metrics\" function to find accuracy and f1 score\n",
    "        accuracy,f1score=evaluation_metrics(predict_y,val_y_tensor)\n",
    "        \n",
    "        print('Epoch %d/%d - Loss_train: %.3f   loss_val: %.3f   accuracy_val: %.3f f1score_val: %.3f   '% \\\n",
    "              (i + 1, epochs,loss.item(),loss_val.item(),accuracy,f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_test: 0.951 f1score_val: 0.951   \n"
     ]
    }
   ],
   "source": [
    "test_x_tensor=torch.tensor(test_x.toarray()).float()\n",
    "test_y_tensor=torch.tensor(test_y)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test set evaluation:\n",
    "    \n",
    "    # compute the output\n",
    "    output_test=net(test_x_tensor)\n",
    "    \n",
    "    # compute the prediction\n",
    "    predict_test_y= output_test.data.max(1, keepdim=True)[1]\n",
    "    \n",
    "    # Use the \"evaluation_metrics\" function to find accuracy and f1 score\n",
    "    accuracy,f1score=evaluation_metrics(predict_test_y,test_y_tensor)\n",
    "    print('Accuracy_test: %.3f f1score_val: %.3f   '% (accuracy,f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
