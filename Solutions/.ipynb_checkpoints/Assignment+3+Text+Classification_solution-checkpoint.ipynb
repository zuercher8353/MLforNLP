{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Task\n",
    "In this task, you would require to claasify the BBC News text into 5 classes ['business' 'entertainment' 'politics' 'sport''tech'] For this task, the code skeleton has been given and you have to write your code in the #TODO part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing relevant libraries \n",
    "If any of the below list libraries is not installed already, then use \"pip install #library_name\" to install it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.6.0 in /Users/ankushpanwar/opt/anaconda3/lib/python3.8/site-packages (1.6.0)\r\n",
      "Requirement already satisfied: future in /Users/ankushpanwar/opt/anaconda3/lib/python3.8/site-packages (from torch==1.6.0) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /Users/ankushpanwar/opt/anaconda3/lib/python3.8/site-packages (from torch==1.6.0) (1.18.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing BBC News Dataset\n",
    "Source data from public data set on BBC news articles:\n",
    "D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006. [PDF] [BibTeX].\n",
    "\n",
    "http://mlg.ucd.ie/datasets/bbc.html\n",
    "\n",
    "Cleaned up version of the Dataset is given as csv file with the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"bbc-text_train.csv\")\n",
    "data_test= pd.read_csv(\"bbc-text_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>farrell due to make us tv debut actor colin fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>china continues rapid growth china s economy h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>ebbers  aware  of worldcom fraud former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>school tribute for tv host carson more than 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>broadband fuels online expression fast web acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0  entertainment  farrell due to make us tv debut actor colin fa...\n",
       "1       business  china continues rapid growth china s economy h...\n",
       "2       business  ebbers  aware  of worldcom fraud former worldc...\n",
       "3  entertainment  school tribute for tv host carson more than 1 ...\n",
       "4           tech  broadband fuels online expression fast web acc..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            413\n",
       "business         409\n",
       "politics         334\n",
       "tech             319\n",
       "entertainment    305\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training data into Train and validation set\n",
    "Note: Validation set is surrogate to test set and while training the network , we evaluate the model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_df,val_x_df,train_y_df,val_y_df = train_test_split(data_train['text'],data_train['category'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding prediction classes/labels into integers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business' 'entertainment' 'politics' 'sport' 'tech']\n"
     ]
    }
   ],
   "source": [
    "le =LabelEncoder()\n",
    "le.fit(train_y_df)\n",
    "print(le.classes_)\n",
    "train_y=le.transform(train_y_df)\n",
    "val_y=le.transform(val_y_df)\n",
    "test_y=le.transform(data_test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting News text into numerical vector using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(train_x_df)\n",
    "train_x=vectorizer.transform(train_x_df)\n",
    "val_x=vectorizer.transform(val_x_df)\n",
    "test_x=vectorizer.transform(data_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 4, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        '''\n",
    "        Defining layers of neural network\n",
    "        '''\n",
    "        self.fc1 = nn.Linear(24295, 64) \n",
    "        self.fc2 = nn.Linear(64, 5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (data_points, num_features)\n",
    "        Returns:\n",
    "            the resulting tensor.\n",
    "        \"\"\"\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net =ClassificationNet()\n",
    "\n",
    "#define learning rate\n",
    "learning_rt=0.5\n",
    "\n",
    "#Construct an optimizer object\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rt)\n",
    "\n",
    "#Construct an loss/criterion object\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "#define number of epochs/ number of training iteration\n",
    "epochs=300\n",
    "\n",
    "#converting train and validation set arrays to tensor\n",
    "train_x_tensor=torch.tensor(train_x.toarray()).float()\n",
    "train_y_tensor=torch.tensor(train_y)\n",
    "val_x_tensor=torch.tensor(val_x.toarray()).float()\n",
    "val_y_tensor=torch.tensor(val_y)\n",
    "\n",
    "\n",
    "def evaluation_metrics(predict_y,ground_truth_y):\n",
    "    '''\n",
    "    Returns accuracy and f1 score metrics for evaluation\n",
    "    '''\n",
    "    accuracy=accuracy_score(ground_truth_y,predict_y)\n",
    "    f1score=f1_score(ground_truth_y,predict_y,average='macro')\n",
    "    \n",
    "    return (accuracy,f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 - Loss_train: 1.628   loss_val: 1.781   accuracy_val: 0.163 f1score_val: 0.056   \n",
      "Epoch 2/300 - Loss_train: 1.748   loss_val: 1.750   accuracy_val: 0.312 f1score_val: 0.179   \n",
      "Epoch 3/300 - Loss_train: 1.789   loss_val: 1.563   accuracy_val: 0.194 f1score_val: 0.077   \n",
      "Epoch 4/300 - Loss_train: 1.556   loss_val: 1.500   accuracy_val: 0.596 f1score_val: 0.505   \n",
      "Epoch 5/300 - Loss_train: 1.491   loss_val: 1.448   accuracy_val: 0.520 f1score_val: 0.387   \n",
      "Epoch 6/300 - Loss_train: 1.435   loss_val: 1.398   accuracy_val: 0.525 f1score_val: 0.404   \n",
      "Epoch 7/300 - Loss_train: 1.383   loss_val: 1.372   accuracy_val: 0.458 f1score_val: 0.359   \n",
      "Epoch 8/300 - Loss_train: 1.352   loss_val: 1.571   accuracy_val: 0.233 f1score_val: 0.076   \n",
      "Epoch 9/300 - Loss_train: 1.562   loss_val: 1.810   accuracy_val: 0.230 f1score_val: 0.075   \n",
      "Epoch 10/300 - Loss_train: 1.784   loss_val: 1.533   accuracy_val: 0.295 f1score_val: 0.225   \n",
      "Epoch 11/300 - Loss_train: 1.521   loss_val: 1.439   accuracy_val: 0.287 f1score_val: 0.185   \n",
      "Epoch 12/300 - Loss_train: 1.432   loss_val: 1.472   accuracy_val: 0.421 f1score_val: 0.374   \n",
      "Epoch 13/300 - Loss_train: 1.446   loss_val: 1.416   accuracy_val: 0.427 f1score_val: 0.243   \n",
      "Epoch 14/300 - Loss_train: 1.409   loss_val: 1.427   accuracy_val: 0.461 f1score_val: 0.430   \n",
      "Epoch 15/300 - Loss_train: 1.401   loss_val: 1.365   accuracy_val: 0.466 f1score_val: 0.363   \n",
      "Epoch 16/300 - Loss_train: 1.360   loss_val: 1.359   accuracy_val: 0.430 f1score_val: 0.327   \n",
      "Epoch 17/300 - Loss_train: 1.335   loss_val: 1.292   accuracy_val: 0.607 f1score_val: 0.559   \n",
      "Epoch 18/300 - Loss_train: 1.270   loss_val: 1.196   accuracy_val: 0.621 f1score_val: 0.553   \n",
      "Epoch 19/300 - Loss_train: 1.171   loss_val: 1.195   accuracy_val: 0.520 f1score_val: 0.475   \n",
      "Epoch 20/300 - Loss_train: 1.165   loss_val: 1.333   accuracy_val: 0.419 f1score_val: 0.364   \n",
      "Epoch 21/300 - Loss_train: 1.305   loss_val: 1.399   accuracy_val: 0.559 f1score_val: 0.415   \n",
      "Epoch 22/300 - Loss_train: 1.393   loss_val: 1.321   accuracy_val: 0.480 f1score_val: 0.456   \n",
      "Epoch 23/300 - Loss_train: 1.286   loss_val: 1.175   accuracy_val: 0.688 f1score_val: 0.645   \n",
      "Epoch 24/300 - Loss_train: 1.157   loss_val: 1.202   accuracy_val: 0.584 f1score_val: 0.515   \n",
      "Epoch 25/300 - Loss_train: 1.148   loss_val: 1.155   accuracy_val: 0.570 f1score_val: 0.486   \n",
      "Epoch 26/300 - Loss_train: 1.144   loss_val: 1.078   accuracy_val: 0.643 f1score_val: 0.625   \n",
      "Epoch 27/300 - Loss_train: 1.031   loss_val: 1.373   accuracy_val: 0.360 f1score_val: 0.262   \n",
      "Epoch 28/300 - Loss_train: 1.352   loss_val: 1.605   accuracy_val: 0.404 f1score_val: 0.267   \n",
      "Epoch 29/300 - Loss_train: 1.582   loss_val: 1.375   accuracy_val: 0.371 f1score_val: 0.380   \n",
      "Epoch 30/300 - Loss_train: 1.342   loss_val: 1.344   accuracy_val: 0.478 f1score_val: 0.386   \n",
      "Epoch 31/300 - Loss_train: 1.347   loss_val: 1.266   accuracy_val: 0.461 f1score_val: 0.377   \n",
      "Epoch 32/300 - Loss_train: 1.231   loss_val: 1.185   accuracy_val: 0.416 f1score_val: 0.331   \n",
      "Epoch 33/300 - Loss_train: 1.158   loss_val: 1.221   accuracy_val: 0.553 f1score_val: 0.452   \n",
      "Epoch 34/300 - Loss_train: 1.188   loss_val: 1.078   accuracy_val: 0.539 f1score_val: 0.481   \n",
      "Epoch 35/300 - Loss_train: 1.043   loss_val: 1.282   accuracy_val: 0.525 f1score_val: 0.499   \n",
      "Epoch 36/300 - Loss_train: 1.236   loss_val: 1.280   accuracy_val: 0.357 f1score_val: 0.277   \n",
      "Epoch 37/300 - Loss_train: 1.256   loss_val: 1.220   accuracy_val: 0.545 f1score_val: 0.504   \n",
      "Epoch 38/300 - Loss_train: 1.190   loss_val: 1.018   accuracy_val: 0.708 f1score_val: 0.695   \n",
      "Epoch 39/300 - Loss_train: 0.982   loss_val: 1.076   accuracy_val: 0.525 f1score_val: 0.505   \n",
      "Epoch 40/300 - Loss_train: 1.043   loss_val: 1.426   accuracy_val: 0.492 f1score_val: 0.392   \n",
      "Epoch 41/300 - Loss_train: 1.387   loss_val: 1.082   accuracy_val: 0.612 f1score_val: 0.610   \n",
      "Epoch 42/300 - Loss_train: 1.050   loss_val: 0.921   accuracy_val: 0.722 f1score_val: 0.638   \n",
      "Epoch 43/300 - Loss_train: 0.901   loss_val: 0.982   accuracy_val: 0.652 f1score_val: 0.642   \n",
      "Epoch 44/300 - Loss_train: 0.934   loss_val: 1.105   accuracy_val: 0.492 f1score_val: 0.426   \n",
      "Epoch 45/300 - Loss_train: 1.053   loss_val: 1.118   accuracy_val: 0.610 f1score_val: 0.570   \n",
      "Epoch 46/300 - Loss_train: 1.063   loss_val: 0.938   accuracy_val: 0.671 f1score_val: 0.647   \n",
      "Epoch 47/300 - Loss_train: 0.905   loss_val: 1.172   accuracy_val: 0.545 f1score_val: 0.488   \n",
      "Epoch 48/300 - Loss_train: 1.108   loss_val: 1.076   accuracy_val: 0.629 f1score_val: 0.582   \n",
      "Epoch 49/300 - Loss_train: 1.039   loss_val: 1.196   accuracy_val: 0.587 f1score_val: 0.563   \n",
      "Epoch 50/300 - Loss_train: 1.121   loss_val: 0.975   accuracy_val: 0.604 f1score_val: 0.553   \n",
      "Epoch 51/300 - Loss_train: 0.941   loss_val: 0.983   accuracy_val: 0.635 f1score_val: 0.577   \n",
      "Epoch 52/300 - Loss_train: 0.923   loss_val: 0.721   accuracy_val: 0.761 f1score_val: 0.755   \n",
      "Epoch 53/300 - Loss_train: 0.673   loss_val: 0.715   accuracy_val: 0.764 f1score_val: 0.761   \n",
      "Epoch 54/300 - Loss_train: 0.656   loss_val: 0.725   accuracy_val: 0.756 f1score_val: 0.746   \n",
      "Epoch 55/300 - Loss_train: 0.659   loss_val: 0.746   accuracy_val: 0.750 f1score_val: 0.736   \n",
      "Epoch 56/300 - Loss_train: 0.683   loss_val: 0.730   accuracy_val: 0.736 f1score_val: 0.727   \n",
      "Epoch 57/300 - Loss_train: 0.649   loss_val: 0.794   accuracy_val: 0.688 f1score_val: 0.655   \n",
      "Epoch 58/300 - Loss_train: 0.720   loss_val: 0.946   accuracy_val: 0.674 f1score_val: 0.660   \n",
      "Epoch 59/300 - Loss_train: 0.855   loss_val: 0.712   accuracy_val: 0.792 f1score_val: 0.790   \n",
      "Epoch 60/300 - Loss_train: 0.644   loss_val: 0.871   accuracy_val: 0.677 f1score_val: 0.655   \n",
      "Epoch 61/300 - Loss_train: 0.778   loss_val: 0.582   accuracy_val: 0.801 f1score_val: 0.798   \n",
      "Epoch 62/300 - Loss_train: 0.495   loss_val: 0.564   accuracy_val: 0.787 f1score_val: 0.781   \n",
      "Epoch 63/300 - Loss_train: 0.480   loss_val: 0.679   accuracy_val: 0.730 f1score_val: 0.727   \n",
      "Epoch 64/300 - Loss_train: 0.550   loss_val: 0.904   accuracy_val: 0.697 f1score_val: 0.669   \n",
      "Epoch 65/300 - Loss_train: 0.860   loss_val: 0.848   accuracy_val: 0.632 f1score_val: 0.591   \n",
      "Epoch 66/300 - Loss_train: 0.740   loss_val: 0.593   accuracy_val: 0.803 f1score_val: 0.796   \n",
      "Epoch 67/300 - Loss_train: 0.534   loss_val: 0.530   accuracy_val: 0.817 f1score_val: 0.816   \n",
      "Epoch 68/300 - Loss_train: 0.425   loss_val: 0.493   accuracy_val: 0.831 f1score_val: 0.821   \n",
      "Epoch 69/300 - Loss_train: 0.415   loss_val: 0.645   accuracy_val: 0.787 f1score_val: 0.777   \n",
      "Epoch 70/300 - Loss_train: 0.546   loss_val: 0.784   accuracy_val: 0.694 f1score_val: 0.662   \n",
      "Epoch 71/300 - Loss_train: 0.722   loss_val: 0.868   accuracy_val: 0.725 f1score_val: 0.660   \n",
      "Epoch 72/300 - Loss_train: 0.820   loss_val: 0.649   accuracy_val: 0.756 f1score_val: 0.753   \n",
      "Epoch 73/300 - Loss_train: 0.574   loss_val: 0.977   accuracy_val: 0.646 f1score_val: 0.583   \n",
      "Epoch 74/300 - Loss_train: 0.895   loss_val: 0.562   accuracy_val: 0.817 f1score_val: 0.808   \n",
      "Epoch 75/300 - Loss_train: 0.465   loss_val: 0.612   accuracy_val: 0.767 f1score_val: 0.761   \n",
      "Epoch 76/300 - Loss_train: 0.546   loss_val: 0.841   accuracy_val: 0.697 f1score_val: 0.637   \n",
      "Epoch 77/300 - Loss_train: 0.739   loss_val: 0.950   accuracy_val: 0.671 f1score_val: 0.605   \n",
      "Epoch 78/300 - Loss_train: 0.858   loss_val: 0.579   accuracy_val: 0.809 f1score_val: 0.808   \n",
      "Epoch 79/300 - Loss_train: 0.477   loss_val: 0.540   accuracy_val: 0.795 f1score_val: 0.778   \n",
      "Epoch 80/300 - Loss_train: 0.464   loss_val: 0.682   accuracy_val: 0.756 f1score_val: 0.760   \n",
      "Epoch 81/300 - Loss_train: 0.560   loss_val: 0.630   accuracy_val: 0.789 f1score_val: 0.759   \n",
      "Epoch 82/300 - Loss_train: 0.538   loss_val: 0.651   accuracy_val: 0.747 f1score_val: 0.747   \n",
      "Epoch 83/300 - Loss_train: 0.541   loss_val: 0.477   accuracy_val: 0.829 f1score_val: 0.811   \n",
      "Epoch 84/300 - Loss_train: 0.399   loss_val: 0.405   accuracy_val: 0.857 f1score_val: 0.854   \n",
      "Epoch 85/300 - Loss_train: 0.312   loss_val: 0.346   accuracy_val: 0.890 f1score_val: 0.884   \n",
      "Epoch 86/300 - Loss_train: 0.253   loss_val: 0.328   accuracy_val: 0.879 f1score_val: 0.874   \n",
      "Epoch 87/300 - Loss_train: 0.243   loss_val: 0.332   accuracy_val: 0.893 f1score_val: 0.888   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300 - Loss_train: 0.235   loss_val: 0.351   accuracy_val: 0.868 f1score_val: 0.861   \n",
      "Epoch 89/300 - Loss_train: 0.263   loss_val: 0.411   accuracy_val: 0.846 f1score_val: 0.843   \n",
      "Epoch 90/300 - Loss_train: 0.298   loss_val: 0.499   accuracy_val: 0.809 f1score_val: 0.794   \n",
      "Epoch 91/300 - Loss_train: 0.392   loss_val: 0.567   accuracy_val: 0.787 f1score_val: 0.783   \n",
      "Epoch 92/300 - Loss_train: 0.441   loss_val: 0.551   accuracy_val: 0.795 f1score_val: 0.767   \n",
      "Epoch 93/300 - Loss_train: 0.464   loss_val: 0.469   accuracy_val: 0.851 f1score_val: 0.831   \n",
      "Epoch 94/300 - Loss_train: 0.395   loss_val: 0.345   accuracy_val: 0.888 f1score_val: 0.884   \n",
      "Epoch 95/300 - Loss_train: 0.253   loss_val: 0.331   accuracy_val: 0.893 f1score_val: 0.885   \n",
      "Epoch 96/300 - Loss_train: 0.260   loss_val: 0.408   accuracy_val: 0.854 f1score_val: 0.849   \n",
      "Epoch 97/300 - Loss_train: 0.284   loss_val: 0.421   accuracy_val: 0.862 f1score_val: 0.848   \n",
      "Epoch 98/300 - Loss_train: 0.367   loss_val: 0.391   accuracy_val: 0.865 f1score_val: 0.854   \n",
      "Epoch 99/300 - Loss_train: 0.283   loss_val: 0.377   accuracy_val: 0.874 f1score_val: 0.863   \n",
      "Epoch 100/300 - Loss_train: 0.311   loss_val: 0.427   accuracy_val: 0.848 f1score_val: 0.823   \n",
      "Epoch 101/300 - Loss_train: 0.319   loss_val: 0.387   accuracy_val: 0.860 f1score_val: 0.856   \n",
      "Epoch 102/300 - Loss_train: 0.299   loss_val: 0.365   accuracy_val: 0.862 f1score_val: 0.846   \n",
      "Epoch 103/300 - Loss_train: 0.266   loss_val: 0.459   accuracy_val: 0.831 f1score_val: 0.825   \n",
      "Epoch 104/300 - Loss_train: 0.342   loss_val: 0.392   accuracy_val: 0.857 f1score_val: 0.839   \n",
      "Epoch 105/300 - Loss_train: 0.294   loss_val: 0.350   accuracy_val: 0.885 f1score_val: 0.880   \n",
      "Epoch 106/300 - Loss_train: 0.244   loss_val: 0.277   accuracy_val: 0.896 f1score_val: 0.890   \n",
      "Epoch 107/300 - Loss_train: 0.178   loss_val: 0.269   accuracy_val: 0.902 f1score_val: 0.897   \n",
      "Epoch 108/300 - Loss_train: 0.171   loss_val: 0.273   accuracy_val: 0.902 f1score_val: 0.896   \n",
      "Epoch 109/300 - Loss_train: 0.168   loss_val: 0.281   accuracy_val: 0.896 f1score_val: 0.893   \n",
      "Epoch 110/300 - Loss_train: 0.179   loss_val: 0.291   accuracy_val: 0.890 f1score_val: 0.884   \n",
      "Epoch 111/300 - Loss_train: 0.183   loss_val: 0.300   accuracy_val: 0.885 f1score_val: 0.883   \n",
      "Epoch 112/300 - Loss_train: 0.193   loss_val: 0.293   accuracy_val: 0.890 f1score_val: 0.883   \n",
      "Epoch 113/300 - Loss_train: 0.187   loss_val: 0.274   accuracy_val: 0.902 f1score_val: 0.900   \n",
      "Epoch 114/300 - Loss_train: 0.172   loss_val: 0.248   accuracy_val: 0.907 f1score_val: 0.903   \n",
      "Epoch 115/300 - Loss_train: 0.148   loss_val: 0.228   accuracy_val: 0.919 f1score_val: 0.915   \n",
      "Epoch 116/300 - Loss_train: 0.131   loss_val: 0.215   accuracy_val: 0.916 f1score_val: 0.911   \n",
      "Epoch 117/300 - Loss_train: 0.120   loss_val: 0.203   accuracy_val: 0.927 f1score_val: 0.924   \n",
      "Epoch 118/300 - Loss_train: 0.111   loss_val: 0.199   accuracy_val: 0.924 f1score_val: 0.920   \n",
      "Epoch 119/300 - Loss_train: 0.105   loss_val: 0.192   accuracy_val: 0.935 f1score_val: 0.932   \n",
      "Epoch 120/300 - Loss_train: 0.101   loss_val: 0.192   accuracy_val: 0.921 f1score_val: 0.917   \n",
      "Epoch 121/300 - Loss_train: 0.098   loss_val: 0.188   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 122/300 - Loss_train: 0.096   loss_val: 0.190   accuracy_val: 0.927 f1score_val: 0.924   \n",
      "Epoch 123/300 - Loss_train: 0.094   loss_val: 0.186   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 124/300 - Loss_train: 0.093   loss_val: 0.189   accuracy_val: 0.930 f1score_val: 0.926   \n",
      "Epoch 125/300 - Loss_train: 0.091   loss_val: 0.184   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 126/300 - Loss_train: 0.090   loss_val: 0.188   accuracy_val: 0.930 f1score_val: 0.926   \n",
      "Epoch 127/300 - Loss_train: 0.088   loss_val: 0.182   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 128/300 - Loss_train: 0.088   loss_val: 0.185   accuracy_val: 0.930 f1score_val: 0.926   \n",
      "Epoch 129/300 - Loss_train: 0.085   loss_val: 0.180   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 130/300 - Loss_train: 0.084   loss_val: 0.182   accuracy_val: 0.930 f1score_val: 0.926   \n",
      "Epoch 131/300 - Loss_train: 0.081   loss_val: 0.176   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 132/300 - Loss_train: 0.080   loss_val: 0.177   accuracy_val: 0.930 f1score_val: 0.926   \n",
      "Epoch 133/300 - Loss_train: 0.077   loss_val: 0.170   accuracy_val: 0.947 f1score_val: 0.945   \n",
      "Epoch 134/300 - Loss_train: 0.075   loss_val: 0.170   accuracy_val: 0.938 f1score_val: 0.935   \n",
      "Epoch 135/300 - Loss_train: 0.071   loss_val: 0.164   accuracy_val: 0.947 f1score_val: 0.944   \n",
      "Epoch 136/300 - Loss_train: 0.069   loss_val: 0.164   accuracy_val: 0.938 f1score_val: 0.935   \n",
      "Epoch 137/300 - Loss_train: 0.066   loss_val: 0.159   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 138/300 - Loss_train: 0.064   loss_val: 0.159   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 139/300 - Loss_train: 0.062   loss_val: 0.155   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 140/300 - Loss_train: 0.060   loss_val: 0.155   accuracy_val: 0.947 f1score_val: 0.944   \n",
      "Epoch 141/300 - Loss_train: 0.059   loss_val: 0.152   accuracy_val: 0.952 f1score_val: 0.951   \n",
      "Epoch 142/300 - Loss_train: 0.058   loss_val: 0.153   accuracy_val: 0.944 f1score_val: 0.941   \n",
      "Epoch 143/300 - Loss_train: 0.056   loss_val: 0.150   accuracy_val: 0.952 f1score_val: 0.951   \n",
      "Epoch 144/300 - Loss_train: 0.055   loss_val: 0.150   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 145/300 - Loss_train: 0.054   loss_val: 0.149   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 146/300 - Loss_train: 0.053   loss_val: 0.149   accuracy_val: 0.947 f1score_val: 0.944   \n",
      "Epoch 147/300 - Loss_train: 0.052   loss_val: 0.147   accuracy_val: 0.949 f1score_val: 0.948   \n",
      "Epoch 148/300 - Loss_train: 0.051   loss_val: 0.147   accuracy_val: 0.949 f1score_val: 0.948   \n",
      "Epoch 149/300 - Loss_train: 0.050   loss_val: 0.146   accuracy_val: 0.949 f1score_val: 0.948   \n",
      "Epoch 150/300 - Loss_train: 0.049   loss_val: 0.145   accuracy_val: 0.949 f1score_val: 0.948   \n",
      "Epoch 151/300 - Loss_train: 0.048   loss_val: 0.144   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 152/300 - Loss_train: 0.047   loss_val: 0.144   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 153/300 - Loss_train: 0.047   loss_val: 0.143   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 154/300 - Loss_train: 0.046   loss_val: 0.142   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 155/300 - Loss_train: 0.045   loss_val: 0.142   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 156/300 - Loss_train: 0.044   loss_val: 0.141   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 157/300 - Loss_train: 0.044   loss_val: 0.141   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 158/300 - Loss_train: 0.043   loss_val: 0.140   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 159/300 - Loss_train: 0.042   loss_val: 0.139   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 160/300 - Loss_train: 0.042   loss_val: 0.139   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 161/300 - Loss_train: 0.041   loss_val: 0.138   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 162/300 - Loss_train: 0.040   loss_val: 0.138   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 163/300 - Loss_train: 0.040   loss_val: 0.137   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 164/300 - Loss_train: 0.039   loss_val: 0.137   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 165/300 - Loss_train: 0.039   loss_val: 0.136   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 166/300 - Loss_train: 0.038   loss_val: 0.136   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 167/300 - Loss_train: 0.037   loss_val: 0.135   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 168/300 - Loss_train: 0.037   loss_val: 0.135   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 169/300 - Loss_train: 0.036   loss_val: 0.134   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 170/300 - Loss_train: 0.036   loss_val: 0.134   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 171/300 - Loss_train: 0.035   loss_val: 0.133   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 172/300 - Loss_train: 0.035   loss_val: 0.133   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 173/300 - Loss_train: 0.034   loss_val: 0.133   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 174/300 - Loss_train: 0.034   loss_val: 0.132   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 175/300 - Loss_train: 0.034   loss_val: 0.132   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 176/300 - Loss_train: 0.033   loss_val: 0.131   accuracy_val: 0.955 f1score_val: 0.953   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/300 - Loss_train: 0.033   loss_val: 0.131   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 178/300 - Loss_train: 0.032   loss_val: 0.131   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 179/300 - Loss_train: 0.032   loss_val: 0.130   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 180/300 - Loss_train: 0.031   loss_val: 0.130   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 181/300 - Loss_train: 0.031   loss_val: 0.129   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 182/300 - Loss_train: 0.031   loss_val: 0.129   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 183/300 - Loss_train: 0.030   loss_val: 0.129   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 184/300 - Loss_train: 0.030   loss_val: 0.128   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 185/300 - Loss_train: 0.030   loss_val: 0.128   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 186/300 - Loss_train: 0.029   loss_val: 0.128   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 187/300 - Loss_train: 0.029   loss_val: 0.128   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 188/300 - Loss_train: 0.029   loss_val: 0.127   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 189/300 - Loss_train: 0.028   loss_val: 0.127   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 190/300 - Loss_train: 0.028   loss_val: 0.127   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 191/300 - Loss_train: 0.028   loss_val: 0.126   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 192/300 - Loss_train: 0.027   loss_val: 0.126   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 193/300 - Loss_train: 0.027   loss_val: 0.126   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 194/300 - Loss_train: 0.027   loss_val: 0.125   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 195/300 - Loss_train: 0.026   loss_val: 0.125   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 196/300 - Loss_train: 0.026   loss_val: 0.125   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 197/300 - Loss_train: 0.026   loss_val: 0.125   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 198/300 - Loss_train: 0.025   loss_val: 0.124   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 199/300 - Loss_train: 0.025   loss_val: 0.124   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 200/300 - Loss_train: 0.025   loss_val: 0.124   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 201/300 - Loss_train: 0.025   loss_val: 0.124   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 202/300 - Loss_train: 0.024   loss_val: 0.123   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 203/300 - Loss_train: 0.024   loss_val: 0.123   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 204/300 - Loss_train: 0.024   loss_val: 0.123   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 205/300 - Loss_train: 0.024   loss_val: 0.123   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 206/300 - Loss_train: 0.023   loss_val: 0.122   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 207/300 - Loss_train: 0.023   loss_val: 0.122   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 208/300 - Loss_train: 0.023   loss_val: 0.122   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 209/300 - Loss_train: 0.023   loss_val: 0.122   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 210/300 - Loss_train: 0.023   loss_val: 0.122   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 211/300 - Loss_train: 0.022   loss_val: 0.121   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 212/300 - Loss_train: 0.022   loss_val: 0.121   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 213/300 - Loss_train: 0.022   loss_val: 0.121   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 214/300 - Loss_train: 0.022   loss_val: 0.121   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 215/300 - Loss_train: 0.022   loss_val: 0.121   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 216/300 - Loss_train: 0.021   loss_val: 0.120   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 217/300 - Loss_train: 0.021   loss_val: 0.120   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 218/300 - Loss_train: 0.021   loss_val: 0.120   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 219/300 - Loss_train: 0.021   loss_val: 0.120   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 220/300 - Loss_train: 0.021   loss_val: 0.120   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 221/300 - Loss_train: 0.020   loss_val: 0.120   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 222/300 - Loss_train: 0.020   loss_val: 0.119   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 223/300 - Loss_train: 0.020   loss_val: 0.119   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 224/300 - Loss_train: 0.020   loss_val: 0.119   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 225/300 - Loss_train: 0.020   loss_val: 0.119   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 226/300 - Loss_train: 0.020   loss_val: 0.119   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 227/300 - Loss_train: 0.019   loss_val: 0.119   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 228/300 - Loss_train: 0.019   loss_val: 0.118   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 229/300 - Loss_train: 0.019   loss_val: 0.118   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 230/300 - Loss_train: 0.019   loss_val: 0.118   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 231/300 - Loss_train: 0.019   loss_val: 0.118   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 232/300 - Loss_train: 0.019   loss_val: 0.118   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 233/300 - Loss_train: 0.018   loss_val: 0.118   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 234/300 - Loss_train: 0.018   loss_val: 0.118   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 235/300 - Loss_train: 0.018   loss_val: 0.117   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 236/300 - Loss_train: 0.018   loss_val: 0.117   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 237/300 - Loss_train: 0.018   loss_val: 0.117   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 238/300 - Loss_train: 0.018   loss_val: 0.117   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 239/300 - Loss_train: 0.018   loss_val: 0.117   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 240/300 - Loss_train: 0.017   loss_val: 0.117   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 241/300 - Loss_train: 0.017   loss_val: 0.117   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 242/300 - Loss_train: 0.017   loss_val: 0.116   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 243/300 - Loss_train: 0.017   loss_val: 0.116   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 244/300 - Loss_train: 0.017   loss_val: 0.116   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 245/300 - Loss_train: 0.017   loss_val: 0.116   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 246/300 - Loss_train: 0.017   loss_val: 0.116   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 247/300 - Loss_train: 0.017   loss_val: 0.116   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 248/300 - Loss_train: 0.016   loss_val: 0.116   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 249/300 - Loss_train: 0.016   loss_val: 0.116   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 250/300 - Loss_train: 0.016   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 251/300 - Loss_train: 0.016   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 252/300 - Loss_train: 0.016   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 253/300 - Loss_train: 0.016   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 254/300 - Loss_train: 0.016   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 255/300 - Loss_train: 0.016   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 256/300 - Loss_train: 0.016   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 257/300 - Loss_train: 0.015   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 258/300 - Loss_train: 0.015   loss_val: 0.115   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 259/300 - Loss_train: 0.015   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 260/300 - Loss_train: 0.015   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 261/300 - Loss_train: 0.015   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 262/300 - Loss_train: 0.015   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 263/300 - Loss_train: 0.015   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 264/300 - Loss_train: 0.015   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 265/300 - Loss_train: 0.015   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 266/300 - Loss_train: 0.015   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/300 - Loss_train: 0.014   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 268/300 - Loss_train: 0.014   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 269/300 - Loss_train: 0.014   loss_val: 0.114   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 270/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 271/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 272/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 273/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 274/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 275/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 276/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 277/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 278/300 - Loss_train: 0.014   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 279/300 - Loss_train: 0.013   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 280/300 - Loss_train: 0.013   loss_val: 0.113   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 281/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 282/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 283/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 284/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 285/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 286/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 287/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 288/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 289/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 290/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 291/300 - Loss_train: 0.013   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 292/300 - Loss_train: 0.012   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 293/300 - Loss_train: 0.012   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 294/300 - Loss_train: 0.012   loss_val: 0.112   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 295/300 - Loss_train: 0.012   loss_val: 0.111   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 296/300 - Loss_train: 0.012   loss_val: 0.111   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 297/300 - Loss_train: 0.012   loss_val: 0.111   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 298/300 - Loss_train: 0.012   loss_val: 0.111   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 299/300 - Loss_train: 0.012   loss_val: 0.111   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 300/300 - Loss_train: 0.012   loss_val: 0.111   accuracy_val: 0.961 f1score_val: 0.959   \n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # the training routine is these 5 steps:\n",
    "    \n",
    "    # step 1. zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # step 2. compute the output\n",
    "    output = net(train_x_tensor)\n",
    "    \n",
    "    # step 3. compute the loss\n",
    "    loss = criterion(output, train_y_tensor)\n",
    "    \n",
    "    # step 4. use loss to produce gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # step 5. use optimizer to take gradient step\n",
    "    optimizer.step() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # validation set evaluation:\n",
    "        \n",
    "        # compute the output\n",
    "        output_val=net(val_x_tensor)\n",
    "        \n",
    "        # compute the loss\n",
    "        loss_val = criterion(output_val, val_y_tensor)\n",
    "        \n",
    "        # compute the prediction\n",
    "        predict_y= output_val.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # Use the \"evaluation_metrics\" function to find accuracy and f1 score\n",
    "        accuracy,f1score=evaluation_metrics(predict_y,val_y_tensor)\n",
    "        \n",
    "        print('Epoch %d/%d - Loss_train: %.3f   loss_val: %.3f   accuracy_val: %.3f f1score_val: %.3f   '% \\\n",
    "              (i + 1, epochs,loss.item(),loss_val.item(),accuracy,f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_test: 0.951 f1score_val: 0.951   \n"
     ]
    }
   ],
   "source": [
    "test_x_tensor=torch.tensor(test_x.toarray()).float()\n",
    "test_y_tensor=torch.tensor(test_y)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test set evaluation:\n",
    "    \n",
    "    # compute the output\n",
    "    output_test=net(test_x_tensor)\n",
    "    \n",
    "    # compute the prediction\n",
    "    predict_test_y= output_test.data.max(1, keepdim=True)[1]\n",
    "    \n",
    "    # Use the \"evaluation_metrics\" function to find accuracy and f1 score\n",
    "    accuracy,f1score=evaluation_metrics(predict_test_y,test_y_tensor)\n",
    "    print('Accuracy_test: %.3f f1score_val: %.3f   '% (accuracy,f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
