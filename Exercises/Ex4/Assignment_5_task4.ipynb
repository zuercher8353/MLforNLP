{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Task\n",
    "In this task, you would require to claasify the BBC News text into 5 classes ['business' 'entertainment' 'politics' 'sport''tech'] For this task, the code skeleton has been given and you have to write your code in the #TODO part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing relevant libraries \n",
    "If any of the below list libraries is not installed already, then use \"pip install #library_name\" to install it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.6.0 in /Users/janoschbaltensperger/opt/anaconda3/lib/python3.7/site-packages (1.6.0)\n",
      "Requirement already satisfied: future in /Users/janoschbaltensperger/opt/anaconda3/lib/python3.7/site-packages (from torch==1.6.0) (0.18.2)\n",
      "Requirement already satisfied: numpy in /Users/janoschbaltensperger/opt/anaconda3/lib/python3.7/site-packages (from torch==1.6.0) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing BBC News Dataset\n",
    "Source data from public data set on BBC news articles:\n",
    "D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006. [PDF] [BibTeX].\n",
    "\n",
    "http://mlg.ucd.ie/datasets/bbc.html\n",
    "\n",
    "Cleaned up version of the Dataset is given as csv file with the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"bbc-text_train.csv\")\n",
    "data_test= pd.read_csv(\"bbc-text_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>farrell due to make us tv debut actor colin fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>china continues rapid growth china s economy h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>ebbers  aware  of worldcom fraud former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>school tribute for tv host carson more than 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>broadband fuels online expression fast web acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0  entertainment  farrell due to make us tv debut actor colin fa...\n",
       "1       business  china continues rapid growth china s economy h...\n",
       "2       business  ebbers  aware  of worldcom fraud former worldc...\n",
       "3  entertainment  school tribute for tv host carson more than 1 ...\n",
       "4           tech  broadband fuels online expression fast web acc..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            413\n",
       "business         409\n",
       "politics         334\n",
       "tech             319\n",
       "entertainment    305\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training data into Train and validation set\n",
    "Note: Validation set is surrogate to test set and while training the network , we evaluate the model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_df,val_x_df,train_y_df,val_y_df = train_test_split(data_train['text'],data_train['category'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding prediction classes/labels into integers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business' 'entertainment' 'politics' 'sport' 'tech']\n"
     ]
    }
   ],
   "source": [
    "le =LabelEncoder()\n",
    "le.fit(train_y_df)\n",
    "print(le.classes_)\n",
    "train_y=le.transform(train_y_df)\n",
    "val_y=le.transform(val_y_df)\n",
    "test_y=le.transform(data_test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting News text into numerical vector using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(train_x_df)\n",
    "train_x=vectorizer.transform(train_x_df)\n",
    "val_x=vectorizer.transform(val_x_df)\n",
    "test_x=vectorizer.transform(data_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 4, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424, 24295)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        '''\n",
    "        Defining layers of neural network\n",
    "        '''\n",
    "        # TODO 1: change network to include three hidden layers with \n",
    "        # hidden dimension 256, 128 and 64 respectively\n",
    "        self.fc1 = nn.Linear(in_features = 24295, out_features = 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 5)\n",
    "        \n",
    "        # TODO 2: Add layer normalization to 1st hidden layer (256 dim)\n",
    "        self.bn1 = nn.LayerNorm(256)\n",
    "        \n",
    "        # TODO 3: Add dropout to 2nd (128 dim) and 3rd hidden (64 dim)\n",
    "        # layers with dropout probability of 0.3 for both layers\n",
    "        self.drop = nn.Dropout(p = 0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (data_points, num_features)\n",
    "        Returns:\n",
    "            the resulting tensor.\n",
    "        \"\"\"\n",
    "        # TODO 4: Modify function call to use modified architecture\n",
    "        # You can use ReLU activation function for all the hidden layers\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.drop(self.fc2(x)))\n",
    "        x = F.relu(self.drop(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = ClassificationNet()\n",
    "\n",
    "#define learning rate\n",
    "# TODO 5: Add learning rate to be used for Adam optimizer \n",
    "# Typically adam_lr = 0.0001 x sgd_lr\n",
    "sgd_lr = 0.5\n",
    "adam_lr = 0.0001 * sgd_lr\n",
    "\n",
    "#Construct an optimizer object\n",
    "# TODO 6: Use Adam optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=adam_lr)\n",
    "\n",
    "#Construct an loss/criterion object\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "#define number of epochs/ number of training iteration\n",
    "epochs=300\n",
    "\n",
    "#converting train and validation set arrays to tensor\n",
    "train_x_tensor=torch.tensor(train_x.toarray()).float()\n",
    "train_y_tensor=torch.tensor(train_y)\n",
    "val_x_tensor=torch.tensor(val_x.toarray()).float()\n",
    "val_y_tensor=torch.tensor(val_y)\n",
    "\n",
    "\n",
    "def evaluation_metrics(predict_y,ground_truth_y):\n",
    "    '''\n",
    "    Returns accuracy and f1 score metrics for evaluation\n",
    "    '''\n",
    "    accuracy=accuracy_score(ground_truth_y,predict_y)\n",
    "    f1score=f1_score(ground_truth_y,predict_y,average='macro')\n",
    "    \n",
    "    return (accuracy,f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 - Loss_train: 1.607   loss_val: 1.591   accuracy_val: 0.233 f1score_val: 0.180   \n",
      "Epoch 2/300 - Loss_train: 1.593   loss_val: 1.582   accuracy_val: 0.292 f1score_val: 0.223   \n",
      "Epoch 3/300 - Loss_train: 1.575   loss_val: 1.565   accuracy_val: 0.346 f1score_val: 0.265   \n",
      "Epoch 4/300 - Loss_train: 1.561   loss_val: 1.561   accuracy_val: 0.334 f1score_val: 0.277   \n",
      "Epoch 5/300 - Loss_train: 1.545   loss_val: 1.542   accuracy_val: 0.407 f1score_val: 0.324   \n",
      "Epoch 6/300 - Loss_train: 1.525   loss_val: 1.526   accuracy_val: 0.455 f1score_val: 0.404   \n",
      "Epoch 7/300 - Loss_train: 1.508   loss_val: 1.517   accuracy_val: 0.497 f1score_val: 0.444   \n",
      "Epoch 8/300 - Loss_train: 1.489   loss_val: 1.494   accuracy_val: 0.559 f1score_val: 0.513   \n",
      "Epoch 9/300 - Loss_train: 1.468   loss_val: 1.475   accuracy_val: 0.576 f1score_val: 0.552   \n",
      "Epoch 10/300 - Loss_train: 1.453   loss_val: 1.465   accuracy_val: 0.598 f1score_val: 0.570   \n",
      "Epoch 11/300 - Loss_train: 1.425   loss_val: 1.449   accuracy_val: 0.640 f1score_val: 0.614   \n",
      "Epoch 12/300 - Loss_train: 1.409   loss_val: 1.431   accuracy_val: 0.674 f1score_val: 0.640   \n",
      "Epoch 13/300 - Loss_train: 1.384   loss_val: 1.420   accuracy_val: 0.666 f1score_val: 0.642   \n",
      "Epoch 14/300 - Loss_train: 1.369   loss_val: 1.393   accuracy_val: 0.697 f1score_val: 0.675   \n",
      "Epoch 15/300 - Loss_train: 1.346   loss_val: 1.384   accuracy_val: 0.736 f1score_val: 0.713   \n",
      "Epoch 16/300 - Loss_train: 1.323   loss_val: 1.365   accuracy_val: 0.685 f1score_val: 0.671   \n",
      "Epoch 17/300 - Loss_train: 1.303   loss_val: 1.356   accuracy_val: 0.747 f1score_val: 0.739   \n",
      "Epoch 18/300 - Loss_train: 1.288   loss_val: 1.326   accuracy_val: 0.770 f1score_val: 0.760   \n",
      "Epoch 19/300 - Loss_train: 1.266   loss_val: 1.317   accuracy_val: 0.770 f1score_val: 0.756   \n",
      "Epoch 20/300 - Loss_train: 1.246   loss_val: 1.304   accuracy_val: 0.775 f1score_val: 0.766   \n",
      "Epoch 21/300 - Loss_train: 1.229   loss_val: 1.291   accuracy_val: 0.803 f1score_val: 0.790   \n",
      "Epoch 22/300 - Loss_train: 1.210   loss_val: 1.266   accuracy_val: 0.815 f1score_val: 0.799   \n",
      "Epoch 23/300 - Loss_train: 1.189   loss_val: 1.250   accuracy_val: 0.806 f1score_val: 0.790   \n",
      "Epoch 24/300 - Loss_train: 1.177   loss_val: 1.242   accuracy_val: 0.803 f1score_val: 0.789   \n",
      "Epoch 25/300 - Loss_train: 1.165   loss_val: 1.226   accuracy_val: 0.837 f1score_val: 0.824   \n",
      "Epoch 26/300 - Loss_train: 1.144   loss_val: 1.212   accuracy_val: 0.848 f1score_val: 0.831   \n",
      "Epoch 27/300 - Loss_train: 1.121   loss_val: 1.188   accuracy_val: 0.860 f1score_val: 0.852   \n",
      "Epoch 28/300 - Loss_train: 1.119   loss_val: 1.192   accuracy_val: 0.857 f1score_val: 0.847   \n",
      "Epoch 29/300 - Loss_train: 1.099   loss_val: 1.172   accuracy_val: 0.860 f1score_val: 0.854   \n",
      "Epoch 30/300 - Loss_train: 1.093   loss_val: 1.177   accuracy_val: 0.871 f1score_val: 0.863   \n",
      "Epoch 31/300 - Loss_train: 1.072   loss_val: 1.157   accuracy_val: 0.854 f1score_val: 0.845   \n",
      "Epoch 32/300 - Loss_train: 1.066   loss_val: 1.148   accuracy_val: 0.879 f1score_val: 0.868   \n",
      "Epoch 33/300 - Loss_train: 1.055   loss_val: 1.122   accuracy_val: 0.882 f1score_val: 0.873   \n",
      "Epoch 34/300 - Loss_train: 1.035   loss_val: 1.108   accuracy_val: 0.876 f1score_val: 0.868   \n",
      "Epoch 35/300 - Loss_train: 1.016   loss_val: 1.118   accuracy_val: 0.876 f1score_val: 0.867   \n",
      "Epoch 36/300 - Loss_train: 1.005   loss_val: 1.098   accuracy_val: 0.876 f1score_val: 0.867   \n",
      "Epoch 37/300 - Loss_train: 0.983   loss_val: 1.095   accuracy_val: 0.879 f1score_val: 0.876   \n",
      "Epoch 38/300 - Loss_train: 0.979   loss_val: 1.087   accuracy_val: 0.890 f1score_val: 0.884   \n",
      "Epoch 39/300 - Loss_train: 0.968   loss_val: 1.053   accuracy_val: 0.921 f1score_val: 0.916   \n",
      "Epoch 40/300 - Loss_train: 0.957   loss_val: 1.064   accuracy_val: 0.893 f1score_val: 0.886   \n",
      "Epoch 41/300 - Loss_train: 0.948   loss_val: 1.040   accuracy_val: 0.899 f1score_val: 0.892   \n",
      "Epoch 42/300 - Loss_train: 0.933   loss_val: 1.031   accuracy_val: 0.899 f1score_val: 0.894   \n",
      "Epoch 43/300 - Loss_train: 0.925   loss_val: 1.016   accuracy_val: 0.893 f1score_val: 0.883   \n",
      "Epoch 44/300 - Loss_train: 0.909   loss_val: 1.001   accuracy_val: 0.921 f1score_val: 0.915   \n",
      "Epoch 45/300 - Loss_train: 0.896   loss_val: 0.995   accuracy_val: 0.916 f1score_val: 0.911   \n",
      "Epoch 46/300 - Loss_train: 0.883   loss_val: 0.991   accuracy_val: 0.919 f1score_val: 0.914   \n",
      "Epoch 47/300 - Loss_train: 0.876   loss_val: 0.996   accuracy_val: 0.874 f1score_val: 0.870   \n",
      "Epoch 48/300 - Loss_train: 0.858   loss_val: 0.976   accuracy_val: 0.907 f1score_val: 0.902   \n",
      "Epoch 49/300 - Loss_train: 0.856   loss_val: 0.970   accuracy_val: 0.904 f1score_val: 0.898   \n",
      "Epoch 50/300 - Loss_train: 0.852   loss_val: 0.957   accuracy_val: 0.910 f1score_val: 0.906   \n",
      "Epoch 51/300 - Loss_train: 0.834   loss_val: 0.937   accuracy_val: 0.907 f1score_val: 0.901   \n",
      "Epoch 52/300 - Loss_train: 0.825   loss_val: 0.946   accuracy_val: 0.907 f1score_val: 0.898   \n",
      "Epoch 53/300 - Loss_train: 0.818   loss_val: 0.936   accuracy_val: 0.902 f1score_val: 0.898   \n",
      "Epoch 54/300 - Loss_train: 0.809   loss_val: 0.915   accuracy_val: 0.930 f1score_val: 0.924   \n",
      "Epoch 55/300 - Loss_train: 0.795   loss_val: 0.911   accuracy_val: 0.921 f1score_val: 0.916   \n",
      "Epoch 56/300 - Loss_train: 0.787   loss_val: 0.914   accuracy_val: 0.935 f1score_val: 0.933   \n",
      "Epoch 57/300 - Loss_train: 0.772   loss_val: 0.894   accuracy_val: 0.921 f1score_val: 0.915   \n",
      "Epoch 58/300 - Loss_train: 0.762   loss_val: 0.886   accuracy_val: 0.924 f1score_val: 0.919   \n",
      "Epoch 59/300 - Loss_train: 0.749   loss_val: 0.881   accuracy_val: 0.921 f1score_val: 0.916   \n",
      "Epoch 60/300 - Loss_train: 0.744   loss_val: 0.882   accuracy_val: 0.919 f1score_val: 0.912   \n",
      "Epoch 61/300 - Loss_train: 0.735   loss_val: 0.861   accuracy_val: 0.949 f1score_val: 0.946   \n",
      "Epoch 62/300 - Loss_train: 0.722   loss_val: 0.855   accuracy_val: 0.927 f1score_val: 0.922   \n",
      "Epoch 63/300 - Loss_train: 0.715   loss_val: 0.871   accuracy_val: 0.910 f1score_val: 0.903   \n",
      "Epoch 64/300 - Loss_train: 0.705   loss_val: 0.841   accuracy_val: 0.927 f1score_val: 0.922   \n",
      "Epoch 65/300 - Loss_train: 0.706   loss_val: 0.827   accuracy_val: 0.927 f1score_val: 0.921   \n",
      "Epoch 66/300 - Loss_train: 0.693   loss_val: 0.820   accuracy_val: 0.935 f1score_val: 0.933   \n",
      "Epoch 67/300 - Loss_train: 0.685   loss_val: 0.808   accuracy_val: 0.947 f1score_val: 0.943   \n",
      "Epoch 68/300 - Loss_train: 0.670   loss_val: 0.811   accuracy_val: 0.944 f1score_val: 0.941   \n",
      "Epoch 69/300 - Loss_train: 0.673   loss_val: 0.798   accuracy_val: 0.924 f1score_val: 0.920   \n",
      "Epoch 70/300 - Loss_train: 0.655   loss_val: 0.789   accuracy_val: 0.941 f1score_val: 0.937   \n",
      "Epoch 71/300 - Loss_train: 0.647   loss_val: 0.776   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 72/300 - Loss_train: 0.638   loss_val: 0.775   accuracy_val: 0.930 f1score_val: 0.927   \n",
      "Epoch 73/300 - Loss_train: 0.637   loss_val: 0.773   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 74/300 - Loss_train: 0.625   loss_val: 0.786   accuracy_val: 0.938 f1score_val: 0.934   \n",
      "Epoch 75/300 - Loss_train: 0.617   loss_val: 0.758   accuracy_val: 0.955 f1score_val: 0.952   \n",
      "Epoch 76/300 - Loss_train: 0.611   loss_val: 0.739   accuracy_val: 0.947 f1score_val: 0.941   \n",
      "Epoch 77/300 - Loss_train: 0.604   loss_val: 0.727   accuracy_val: 0.944 f1score_val: 0.940   \n",
      "Epoch 78/300 - Loss_train: 0.595   loss_val: 0.734   accuracy_val: 0.930 f1score_val: 0.927   \n",
      "Epoch 79/300 - Loss_train: 0.592   loss_val: 0.759   accuracy_val: 0.930 f1score_val: 0.925   \n",
      "Epoch 80/300 - Loss_train: 0.583   loss_val: 0.727   accuracy_val: 0.961 f1score_val: 0.957   \n",
      "Epoch 81/300 - Loss_train: 0.566   loss_val: 0.707   accuracy_val: 0.944 f1score_val: 0.941   \n",
      "Epoch 82/300 - Loss_train: 0.571   loss_val: 0.713   accuracy_val: 0.924 f1score_val: 0.920   \n",
      "Epoch 83/300 - Loss_train: 0.558   loss_val: 0.706   accuracy_val: 0.935 f1score_val: 0.932   \n",
      "Epoch 84/300 - Loss_train: 0.555   loss_val: 0.680   accuracy_val: 0.952 f1score_val: 0.949   \n",
      "Epoch 85/300 - Loss_train: 0.544   loss_val: 0.681   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 86/300 - Loss_train: 0.541   loss_val: 0.681   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 87/300 - Loss_train: 0.532   loss_val: 0.680   accuracy_val: 0.949 f1score_val: 0.946   \n",
      "Epoch 88/300 - Loss_train: 0.516   loss_val: 0.679   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 89/300 - Loss_train: 0.525   loss_val: 0.658   accuracy_val: 0.944 f1score_val: 0.941   \n",
      "Epoch 90/300 - Loss_train: 0.508   loss_val: 0.680   accuracy_val: 0.933 f1score_val: 0.929   \n",
      "Epoch 91/300 - Loss_train: 0.506   loss_val: 0.663   accuracy_val: 0.944 f1score_val: 0.942   \n",
      "Epoch 92/300 - Loss_train: 0.509   loss_val: 0.636   accuracy_val: 0.949 f1score_val: 0.946   \n",
      "Epoch 93/300 - Loss_train: 0.495   loss_val: 0.656   accuracy_val: 0.952 f1score_val: 0.949   \n",
      "Epoch 94/300 - Loss_train: 0.478   loss_val: 0.642   accuracy_val: 0.947 f1score_val: 0.943   \n",
      "Epoch 95/300 - Loss_train: 0.484   loss_val: 0.641   accuracy_val: 0.944 f1score_val: 0.940   \n",
      "Epoch 96/300 - Loss_train: 0.485   loss_val: 0.624   accuracy_val: 0.952 f1score_val: 0.949   \n",
      "Epoch 97/300 - Loss_train: 0.471   loss_val: 0.624   accuracy_val: 0.941 f1score_val: 0.939   \n",
      "Epoch 98/300 - Loss_train: 0.457   loss_val: 0.593   accuracy_val: 0.949 f1score_val: 0.947   \n",
      "Epoch 99/300 - Loss_train: 0.460   loss_val: 0.615   accuracy_val: 0.949 f1score_val: 0.946   \n",
      "Epoch 100/300 - Loss_train: 0.454   loss_val: 0.620   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 101/300 - Loss_train: 0.440   loss_val: 0.584   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 102/300 - Loss_train: 0.437   loss_val: 0.589   accuracy_val: 0.947 f1score_val: 0.944   \n",
      "Epoch 103/300 - Loss_train: 0.436   loss_val: 0.587   accuracy_val: 0.938 f1score_val: 0.934   \n",
      "Epoch 104/300 - Loss_train: 0.426   loss_val: 0.585   accuracy_val: 0.947 f1score_val: 0.944   \n",
      "Epoch 105/300 - Loss_train: 0.425   loss_val: 0.586   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 106/300 - Loss_train: 0.409   loss_val: 0.578   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 107/300 - Loss_train: 0.418   loss_val: 0.570   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 108/300 - Loss_train: 0.403   loss_val: 0.561   accuracy_val: 0.949 f1score_val: 0.948   \n",
      "Epoch 109/300 - Loss_train: 0.411   loss_val: 0.554   accuracy_val: 0.947 f1score_val: 0.943   \n",
      "Epoch 110/300 - Loss_train: 0.391   loss_val: 0.548   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 111/300 - Loss_train: 0.390   loss_val: 0.535   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 112/300 - Loss_train: 0.380   loss_val: 0.519   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 113/300 - Loss_train: 0.389   loss_val: 0.546   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 114/300 - Loss_train: 0.377   loss_val: 0.540   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 115/300 - Loss_train: 0.365   loss_val: 0.516   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 116/300 - Loss_train: 0.371   loss_val: 0.520   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 117/300 - Loss_train: 0.358   loss_val: 0.513   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 118/300 - Loss_train: 0.360   loss_val: 0.526   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 119/300 - Loss_train: 0.356   loss_val: 0.529   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 120/300 - Loss_train: 0.345   loss_val: 0.501   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 121/300 - Loss_train: 0.346   loss_val: 0.478   accuracy_val: 0.952 f1score_val: 0.951   \n",
      "Epoch 122/300 - Loss_train: 0.344   loss_val: 0.494   accuracy_val: 0.941 f1score_val: 0.938   \n",
      "Epoch 123/300 - Loss_train: 0.327   loss_val: 0.480   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 124/300 - Loss_train: 0.333   loss_val: 0.488   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 125/300 - Loss_train: 0.325   loss_val: 0.496   accuracy_val: 0.944 f1score_val: 0.941   \n",
      "Epoch 126/300 - Loss_train: 0.321   loss_val: 0.468   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 127/300 - Loss_train: 0.316   loss_val: 0.471   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 128/300 - Loss_train: 0.312   loss_val: 0.485   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 129/300 - Loss_train: 0.306   loss_val: 0.499   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 130/300 - Loss_train: 0.308   loss_val: 0.483   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 131/300 - Loss_train: 0.296   loss_val: 0.470   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 132/300 - Loss_train: 0.289   loss_val: 0.466   accuracy_val: 0.952 f1score_val: 0.949   \n",
      "Epoch 133/300 - Loss_train: 0.290   loss_val: 0.460   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 134/300 - Loss_train: 0.300   loss_val: 0.444   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 135/300 - Loss_train: 0.283   loss_val: 0.438   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 136/300 - Loss_train: 0.285   loss_val: 0.449   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 137/300 - Loss_train: 0.273   loss_val: 0.452   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 138/300 - Loss_train: 0.274   loss_val: 0.441   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 139/300 - Loss_train: 0.272   loss_val: 0.443   accuracy_val: 0.958 f1score_val: 0.954   \n",
      "Epoch 140/300 - Loss_train: 0.266   loss_val: 0.426   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 141/300 - Loss_train: 0.257   loss_val: 0.427   accuracy_val: 0.949 f1score_val: 0.946   \n",
      "Epoch 142/300 - Loss_train: 0.262   loss_val: 0.424   accuracy_val: 0.952 f1score_val: 0.949   \n",
      "Epoch 143/300 - Loss_train: 0.259   loss_val: 0.407   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 144/300 - Loss_train: 0.255   loss_val: 0.407   accuracy_val: 0.955 f1score_val: 0.952   \n",
      "Epoch 145/300 - Loss_train: 0.252   loss_val: 0.418   accuracy_val: 0.955 f1score_val: 0.952   \n",
      "Epoch 146/300 - Loss_train: 0.250   loss_val: 0.395   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 147/300 - Loss_train: 0.246   loss_val: 0.401   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 148/300 - Loss_train: 0.246   loss_val: 0.423   accuracy_val: 0.935 f1score_val: 0.931   \n",
      "Epoch 149/300 - Loss_train: 0.244   loss_val: 0.403   accuracy_val: 0.949 f1score_val: 0.947   \n",
      "Epoch 150/300 - Loss_train: 0.242   loss_val: 0.385   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 151/300 - Loss_train: 0.241   loss_val: 0.399   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 152/300 - Loss_train: 0.238   loss_val: 0.411   accuracy_val: 0.949 f1score_val: 0.948   \n",
      "Epoch 153/300 - Loss_train: 0.228   loss_val: 0.393   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 154/300 - Loss_train: 0.224   loss_val: 0.382   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 155/300 - Loss_train: 0.232   loss_val: 0.377   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 156/300 - Loss_train: 0.222   loss_val: 0.367   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 157/300 - Loss_train: 0.222   loss_val: 0.374   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 158/300 - Loss_train: 0.215   loss_val: 0.369   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 159/300 - Loss_train: 0.213   loss_val: 0.351   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 160/300 - Loss_train: 0.208   loss_val: 0.364   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 161/300 - Loss_train: 0.212   loss_val: 0.363   accuracy_val: 0.955 f1score_val: 0.954   \n",
      "Epoch 162/300 - Loss_train: 0.199   loss_val: 0.343   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 163/300 - Loss_train: 0.201   loss_val: 0.367   accuracy_val: 0.961 f1score_val: 0.960   \n",
      "Epoch 164/300 - Loss_train: 0.199   loss_val: 0.355   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 165/300 - Loss_train: 0.199   loss_val: 0.341   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 166/300 - Loss_train: 0.199   loss_val: 0.362   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 167/300 - Loss_train: 0.189   loss_val: 0.345   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 168/300 - Loss_train: 0.194   loss_val: 0.335   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 169/300 - Loss_train: 0.185   loss_val: 0.338   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 170/300 - Loss_train: 0.183   loss_val: 0.345   accuracy_val: 0.955 f1score_val: 0.954   \n",
      "Epoch 171/300 - Loss_train: 0.183   loss_val: 0.329   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 172/300 - Loss_train: 0.181   loss_val: 0.334   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 173/300 - Loss_train: 0.179   loss_val: 0.338   accuracy_val: 0.955 f1score_val: 0.952   \n",
      "Epoch 174/300 - Loss_train: 0.172   loss_val: 0.323   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 175/300 - Loss_train: 0.176   loss_val: 0.333   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 176/300 - Loss_train: 0.171   loss_val: 0.326   accuracy_val: 0.961 f1score_val: 0.960   \n",
      "Epoch 177/300 - Loss_train: 0.173   loss_val: 0.322   accuracy_val: 0.961 f1score_val: 0.960   \n",
      "Epoch 178/300 - Loss_train: 0.161   loss_val: 0.301   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 179/300 - Loss_train: 0.165   loss_val: 0.323   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 180/300 - Loss_train: 0.165   loss_val: 0.333   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 181/300 - Loss_train: 0.161   loss_val: 0.312   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 182/300 - Loss_train: 0.157   loss_val: 0.313   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 183/300 - Loss_train: 0.163   loss_val: 0.309   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 184/300 - Loss_train: 0.158   loss_val: 0.307   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 185/300 - Loss_train: 0.152   loss_val: 0.311   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 186/300 - Loss_train: 0.156   loss_val: 0.297   accuracy_val: 0.961 f1score_val: 0.956   \n",
      "Epoch 187/300 - Loss_train: 0.154   loss_val: 0.300   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 188/300 - Loss_train: 0.145   loss_val: 0.319   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 189/300 - Loss_train: 0.152   loss_val: 0.288   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 190/300 - Loss_train: 0.148   loss_val: 0.292   accuracy_val: 0.955 f1score_val: 0.954   \n",
      "Epoch 191/300 - Loss_train: 0.142   loss_val: 0.294   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 192/300 - Loss_train: 0.142   loss_val: 0.295   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 193/300 - Loss_train: 0.142   loss_val: 0.291   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 194/300 - Loss_train: 0.141   loss_val: 0.291   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 195/300 - Loss_train: 0.136   loss_val: 0.289   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 196/300 - Loss_train: 0.135   loss_val: 0.285   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 197/300 - Loss_train: 0.133   loss_val: 0.289   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 198/300 - Loss_train: 0.134   loss_val: 0.273   accuracy_val: 0.978 f1score_val: 0.977   \n",
      "Epoch 199/300 - Loss_train: 0.133   loss_val: 0.271   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 200/300 - Loss_train: 0.128   loss_val: 0.267   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 201/300 - Loss_train: 0.132   loss_val: 0.281   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 202/300 - Loss_train: 0.128   loss_val: 0.279   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 203/300 - Loss_train: 0.127   loss_val: 0.271   accuracy_val: 0.963 f1score_val: 0.963   \n",
      "Epoch 204/300 - Loss_train: 0.124   loss_val: 0.268   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 205/300 - Loss_train: 0.128   loss_val: 0.243   accuracy_val: 0.961 f1score_val: 0.960   \n",
      "Epoch 206/300 - Loss_train: 0.124   loss_val: 0.263   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 207/300 - Loss_train: 0.118   loss_val: 0.260   accuracy_val: 0.958 f1score_val: 0.957   \n",
      "Epoch 208/300 - Loss_train: 0.125   loss_val: 0.254   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 209/300 - Loss_train: 0.120   loss_val: 0.250   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 210/300 - Loss_train: 0.119   loss_val: 0.280   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 211/300 - Loss_train: 0.117   loss_val: 0.259   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 212/300 - Loss_train: 0.114   loss_val: 0.242   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 213/300 - Loss_train: 0.116   loss_val: 0.263   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 214/300 - Loss_train: 0.112   loss_val: 0.255   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 215/300 - Loss_train: 0.106   loss_val: 0.266   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 216/300 - Loss_train: 0.118   loss_val: 0.255   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 217/300 - Loss_train: 0.108   loss_val: 0.245   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 218/300 - Loss_train: 0.106   loss_val: 0.265   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 219/300 - Loss_train: 0.105   loss_val: 0.252   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 220/300 - Loss_train: 0.106   loss_val: 0.242   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 221/300 - Loss_train: 0.103   loss_val: 0.242   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 222/300 - Loss_train: 0.107   loss_val: 0.243   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 223/300 - Loss_train: 0.098   loss_val: 0.243   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 224/300 - Loss_train: 0.099   loss_val: 0.229   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 225/300 - Loss_train: 0.102   loss_val: 0.225   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 226/300 - Loss_train: 0.100   loss_val: 0.230   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 227/300 - Loss_train: 0.101   loss_val: 0.229   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 228/300 - Loss_train: 0.099   loss_val: 0.218   accuracy_val: 0.983 f1score_val: 0.982   \n",
      "Epoch 229/300 - Loss_train: 0.099   loss_val: 0.237   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 230/300 - Loss_train: 0.092   loss_val: 0.240   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 231/300 - Loss_train: 0.098   loss_val: 0.221   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 232/300 - Loss_train: 0.099   loss_val: 0.244   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 233/300 - Loss_train: 0.089   loss_val: 0.228   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 234/300 - Loss_train: 0.090   loss_val: 0.238   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 235/300 - Loss_train: 0.090   loss_val: 0.232   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 236/300 - Loss_train: 0.086   loss_val: 0.224   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 237/300 - Loss_train: 0.086   loss_val: 0.228   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 238/300 - Loss_train: 0.086   loss_val: 0.211   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 239/300 - Loss_train: 0.085   loss_val: 0.231   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 240/300 - Loss_train: 0.090   loss_val: 0.218   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 241/300 - Loss_train: 0.090   loss_val: 0.209   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 242/300 - Loss_train: 0.085   loss_val: 0.225   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 243/300 - Loss_train: 0.082   loss_val: 0.224   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 244/300 - Loss_train: 0.082   loss_val: 0.226   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 245/300 - Loss_train: 0.082   loss_val: 0.213   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 246/300 - Loss_train: 0.082   loss_val: 0.221   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 247/300 - Loss_train: 0.082   loss_val: 0.223   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 248/300 - Loss_train: 0.080   loss_val: 0.223   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 249/300 - Loss_train: 0.079   loss_val: 0.216   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 250/300 - Loss_train: 0.077   loss_val: 0.225   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 251/300 - Loss_train: 0.075   loss_val: 0.211   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 252/300 - Loss_train: 0.078   loss_val: 0.219   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 253/300 - Loss_train: 0.076   loss_val: 0.215   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 254/300 - Loss_train: 0.075   loss_val: 0.200   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 255/300 - Loss_train: 0.075   loss_val: 0.221   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 256/300 - Loss_train: 0.077   loss_val: 0.215   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 257/300 - Loss_train: 0.076   loss_val: 0.208   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 258/300 - Loss_train: 0.072   loss_val: 0.207   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 259/300 - Loss_train: 0.069   loss_val: 0.225   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 260/300 - Loss_train: 0.073   loss_val: 0.197   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 261/300 - Loss_train: 0.071   loss_val: 0.217   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 262/300 - Loss_train: 0.071   loss_val: 0.203   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 263/300 - Loss_train: 0.067   loss_val: 0.197   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 264/300 - Loss_train: 0.070   loss_val: 0.201   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 265/300 - Loss_train: 0.071   loss_val: 0.196   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 266/300 - Loss_train: 0.069   loss_val: 0.201   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 267/300 - Loss_train: 0.072   loss_val: 0.207   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 268/300 - Loss_train: 0.069   loss_val: 0.203   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 269/300 - Loss_train: 0.069   loss_val: 0.204   accuracy_val: 0.955 f1score_val: 0.952   \n",
      "Epoch 270/300 - Loss_train: 0.064   loss_val: 0.193   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 271/300 - Loss_train: 0.062   loss_val: 0.193   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 272/300 - Loss_train: 0.067   loss_val: 0.180   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 273/300 - Loss_train: 0.069   loss_val: 0.195   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 274/300 - Loss_train: 0.064   loss_val: 0.188   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 275/300 - Loss_train: 0.061   loss_val: 0.186   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 276/300 - Loss_train: 0.064   loss_val: 0.188   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 277/300 - Loss_train: 0.062   loss_val: 0.188   accuracy_val: 0.975 f1score_val: 0.972   \n",
      "Epoch 278/300 - Loss_train: 0.061   loss_val: 0.190   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 279/300 - Loss_train: 0.062   loss_val: 0.202   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 280/300 - Loss_train: 0.063   loss_val: 0.196   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 281/300 - Loss_train: 0.061   loss_val: 0.188   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 282/300 - Loss_train: 0.060   loss_val: 0.199   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 283/300 - Loss_train: 0.057   loss_val: 0.196   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 284/300 - Loss_train: 0.057   loss_val: 0.202   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 285/300 - Loss_train: 0.060   loss_val: 0.181   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 286/300 - Loss_train: 0.054   loss_val: 0.186   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 287/300 - Loss_train: 0.056   loss_val: 0.188   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 288/300 - Loss_train: 0.055   loss_val: 0.183   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 289/300 - Loss_train: 0.057   loss_val: 0.171   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 290/300 - Loss_train: 0.055   loss_val: 0.186   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 291/300 - Loss_train: 0.053   loss_val: 0.181   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 292/300 - Loss_train: 0.054   loss_val: 0.190   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 293/300 - Loss_train: 0.052   loss_val: 0.188   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 294/300 - Loss_train: 0.057   loss_val: 0.177   accuracy_val: 0.975 f1score_val: 0.974   \n",
      "Epoch 295/300 - Loss_train: 0.053   loss_val: 0.172   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 296/300 - Loss_train: 0.049   loss_val: 0.197   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 297/300 - Loss_train: 0.055   loss_val: 0.179   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 298/300 - Loss_train: 0.052   loss_val: 0.190   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 299/300 - Loss_train: 0.051   loss_val: 0.196   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 300/300 - Loss_train: 0.049   loss_val: 0.170   accuracy_val: 0.963 f1score_val: 0.962   \n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # the training routine is these 5 steps:\n",
    "    \n",
    "    # step 1. zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # step 2. compute the output\n",
    "    output = net(train_x_tensor)\n",
    "    \n",
    "    # step 3. compute the loss\n",
    "    loss = criterion(output, train_y_tensor)\n",
    "    \n",
    "    # step 4. use loss to produce gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # step 5. use optimizer to take gradient step\n",
    "    optimizer.step() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # validation set evaluation:\n",
    "        \n",
    "        # compute the output\n",
    "        output_val=net(val_x_tensor)\n",
    "        \n",
    "        # compute the loss\n",
    "        loss_val = criterion(output_val, val_y_tensor)\n",
    "        \n",
    "        # compute the prediction\n",
    "        predict_y= output_val.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # Use the \"evaluation_metrics\" function to find accuracy and f1 score\n",
    "        accuracy,f1score=evaluation_metrics(predict_y,val_y_tensor)\n",
    "        \n",
    "        print('Epoch %d/%d - Loss_train: %.3f   loss_val: %.3f   accuracy_val: %.3f f1score_val: %.3f   '% \\\n",
    "              (i + 1, epochs,loss.item(),loss_val.item(),accuracy,f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_test: 0.969 f1score_val: 0.968   \n"
     ]
    }
   ],
   "source": [
    "test_x_tensor=torch.tensor(test_x.toarray()).float()\n",
    "test_y_tensor=torch.tensor(test_y)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test set evaluation:\n",
    "    \n",
    "    # compute the output\n",
    "    output_test=net(test_x_tensor)\n",
    "    \n",
    "    # compute the prediction\n",
    "    predict_test_y= output_test.data.max(1, keepdim=True)[1]\n",
    "    \n",
    "    # Use the \"evaluation_metrics\" function to find accuracy and f1 score\n",
    "    accuracy,f1score=evaluation_metrics(predict_test_y,test_y_tensor)\n",
    "    print('Accuracy_test: %.3f f1score_val: %.3f   '% (accuracy,f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
