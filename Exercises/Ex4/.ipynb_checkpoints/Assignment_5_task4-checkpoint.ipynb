{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Task\n",
    "In this task, you would require to claasify the BBC News text into 5 classes ['business' 'entertainment' 'politics' 'sport''tech'] For this task, the code skeleton has been given and you have to write your code in the #TODO part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing relevant libraries \n",
    "If any of the below list libraries is not installed already, then use \"pip install #library_name\" to install it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.6.0 in /Users/janoschbaltensperger/opt/anaconda3/lib/python3.7/site-packages (1.6.0)\r\n",
      "Requirement already satisfied: numpy in /Users/janoschbaltensperger/opt/anaconda3/lib/python3.7/site-packages (from torch==1.6.0) (1.18.1)\r\n",
      "Requirement already satisfied: future in /Users/janoschbaltensperger/opt/anaconda3/lib/python3.7/site-packages (from torch==1.6.0) (0.18.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing BBC News Dataset\n",
    "Source data from public data set on BBC news articles:\n",
    "D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006. [PDF] [BibTeX].\n",
    "\n",
    "http://mlg.ucd.ie/datasets/bbc.html\n",
    "\n",
    "Cleaned up version of the Dataset is given as csv file with the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"bbc-text_train.csv\")\n",
    "data_test= pd.read_csv(\"bbc-text_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>farrell due to make us tv debut actor colin fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>china continues rapid growth china s economy h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>ebbers  aware  of worldcom fraud former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>school tribute for tv host carson more than 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>broadband fuels online expression fast web acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0  entertainment  farrell due to make us tv debut actor colin fa...\n",
       "1       business  china continues rapid growth china s economy h...\n",
       "2       business  ebbers  aware  of worldcom fraud former worldc...\n",
       "3  entertainment  school tribute for tv host carson more than 1 ...\n",
       "4           tech  broadband fuels online expression fast web acc..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            413\n",
       "business         409\n",
       "politics         334\n",
       "tech             319\n",
       "entertainment    305\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training data into Train and validation set\n",
    "Note: Validation set is surrogate to test set and while training the network , we evaluate the model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_df,val_x_df,train_y_df,val_y_df = train_test_split(data_train['text'],data_train['category'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding prediction classes/labels into integers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business' 'entertainment' 'politics' 'sport' 'tech']\n"
     ]
    }
   ],
   "source": [
    "le =LabelEncoder()\n",
    "le.fit(train_y_df)\n",
    "print(le.classes_)\n",
    "train_y=le.transform(train_y_df)\n",
    "val_y=le.transform(val_y_df)\n",
    "test_y=le.transform(data_test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting News text into numerical vector using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(train_x_df)\n",
    "train_x=vectorizer.transform(train_x_df)\n",
    "val_x=vectorizer.transform(val_x_df)\n",
    "test_x=vectorizer.transform(data_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 4, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424, 24295)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        '''\n",
    "        Defining layers of neural network\n",
    "        '''\n",
    "        # TODO 1: change network to include three hidden layers with \n",
    "        # hidden dimension 256, 128 and 64 respectively\n",
    "        self.fc1 = nn.Linear(in_features = 24295, out_features = 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 5)\n",
    "        \n",
    "        # TODO 2: Add layer normalization to 1st hidden layer (256 dim)\n",
    "        self.bn1 = nn.LayerNorm(256)\n",
    "        #self.bn1 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # TODO 3: Add dropout to 2nd (128 dim) and 3rd hidden (64 dim)\n",
    "        # layers with dropout probability of 0.3 for both layers\n",
    "        self.drop = nn.Dropout(p = 0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (data_points, num_features)\n",
    "        Returns:\n",
    "            the resulting tensor.\n",
    "        \"\"\"\n",
    "        # TODO 4: Modify function call to use modified architecture\n",
    "        # You can use ReLU activation function for all the hidden layers\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.drop(self.fc2(x)))\n",
    "        x = F.relu(self.drop(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = ClassificationNet()\n",
    "\n",
    "#define learning rate\n",
    "# TODO 5: Add learning rate to be used for Adam optimizer \n",
    "# Typically adam_lr = 0.0001 x sgd_lr\n",
    "sgd_lr = 0.6\n",
    "adam_lr = 0.0001 * sgd_lr\n",
    "\n",
    "#sgd 0.05 => 0.909, 0.5 => 0.965\n",
    "\n",
    "#Construct an optimizer object\n",
    "# TODO 6: Use Adam optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=adam_lr)\n",
    "\n",
    "#Construct an loss/criterion object\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "#define number of epochs/ number of training iteration\n",
    "epochs=300\n",
    "\n",
    "#converting train and validation set arrays to tensor\n",
    "train_x_tensor=torch.tensor(train_x.toarray()).float()\n",
    "train_y_tensor=torch.tensor(train_y)\n",
    "val_x_tensor=torch.tensor(val_x.toarray()).float()\n",
    "val_y_tensor=torch.tensor(val_y)\n",
    "\n",
    "\n",
    "def evaluation_metrics(predict_y,ground_truth_y):\n",
    "    '''\n",
    "    Returns accuracy and f1 score metrics for evaluation\n",
    "    '''\n",
    "    accuracy=accuracy_score(ground_truth_y,predict_y)\n",
    "    f1score=f1_score(ground_truth_y,predict_y,average='macro')\n",
    "    \n",
    "    return (accuracy,f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 - Loss_train: 1.617   loss_val: 1.601   accuracy_val: 0.230 f1score_val: 0.179   \n",
      "Epoch 2/300 - Loss_train: 1.596   loss_val: 1.581   accuracy_val: 0.284 f1score_val: 0.234   \n",
      "Epoch 3/300 - Loss_train: 1.578   loss_val: 1.564   accuracy_val: 0.334 f1score_val: 0.289   \n",
      "Epoch 4/300 - Loss_train: 1.556   loss_val: 1.552   accuracy_val: 0.393 f1score_val: 0.358   \n",
      "Epoch 5/300 - Loss_train: 1.534   loss_val: 1.540   accuracy_val: 0.385 f1score_val: 0.350   \n",
      "Epoch 6/300 - Loss_train: 1.517   loss_val: 1.516   accuracy_val: 0.486 f1score_val: 0.457   \n",
      "Epoch 7/300 - Loss_train: 1.494   loss_val: 1.507   accuracy_val: 0.506 f1score_val: 0.494   \n",
      "Epoch 8/300 - Loss_train: 1.476   loss_val: 1.486   accuracy_val: 0.545 f1score_val: 0.523   \n",
      "Epoch 9/300 - Loss_train: 1.452   loss_val: 1.466   accuracy_val: 0.590 f1score_val: 0.581   \n",
      "Epoch 10/300 - Loss_train: 1.428   loss_val: 1.448   accuracy_val: 0.610 f1score_val: 0.604   \n",
      "Epoch 11/300 - Loss_train: 1.406   loss_val: 1.433   accuracy_val: 0.632 f1score_val: 0.618   \n",
      "Epoch 12/300 - Loss_train: 1.382   loss_val: 1.420   accuracy_val: 0.654 f1score_val: 0.642   \n",
      "Epoch 13/300 - Loss_train: 1.364   loss_val: 1.393   accuracy_val: 0.694 f1score_val: 0.687   \n",
      "Epoch 14/300 - Loss_train: 1.337   loss_val: 1.396   accuracy_val: 0.697 f1score_val: 0.698   \n",
      "Epoch 15/300 - Loss_train: 1.321   loss_val: 1.359   accuracy_val: 0.781 f1score_val: 0.778   \n",
      "Epoch 16/300 - Loss_train: 1.304   loss_val: 1.347   accuracy_val: 0.753 f1score_val: 0.751   \n",
      "Epoch 17/300 - Loss_train: 1.275   loss_val: 1.331   accuracy_val: 0.784 f1score_val: 0.780   \n",
      "Epoch 18/300 - Loss_train: 1.265   loss_val: 1.316   accuracy_val: 0.753 f1score_val: 0.749   \n",
      "Epoch 19/300 - Loss_train: 1.245   loss_val: 1.315   accuracy_val: 0.792 f1score_val: 0.787   \n",
      "Epoch 20/300 - Loss_train: 1.229   loss_val: 1.293   accuracy_val: 0.787 f1score_val: 0.777   \n",
      "Epoch 21/300 - Loss_train: 1.206   loss_val: 1.261   accuracy_val: 0.817 f1score_val: 0.813   \n",
      "Epoch 22/300 - Loss_train: 1.188   loss_val: 1.247   accuracy_val: 0.820 f1score_val: 0.814   \n",
      "Epoch 23/300 - Loss_train: 1.170   loss_val: 1.238   accuracy_val: 0.860 f1score_val: 0.856   \n",
      "Epoch 24/300 - Loss_train: 1.159   loss_val: 1.234   accuracy_val: 0.826 f1score_val: 0.820   \n",
      "Epoch 25/300 - Loss_train: 1.139   loss_val: 1.228   accuracy_val: 0.843 f1score_val: 0.839   \n",
      "Epoch 26/300 - Loss_train: 1.121   loss_val: 1.204   accuracy_val: 0.843 f1score_val: 0.838   \n",
      "Epoch 27/300 - Loss_train: 1.106   loss_val: 1.176   accuracy_val: 0.902 f1score_val: 0.898   \n",
      "Epoch 28/300 - Loss_train: 1.085   loss_val: 1.157   accuracy_val: 0.888 f1score_val: 0.885   \n",
      "Epoch 29/300 - Loss_train: 1.069   loss_val: 1.162   accuracy_val: 0.860 f1score_val: 0.857   \n",
      "Epoch 30/300 - Loss_train: 1.064   loss_val: 1.146   accuracy_val: 0.879 f1score_val: 0.875   \n",
      "Epoch 31/300 - Loss_train: 1.036   loss_val: 1.111   accuracy_val: 0.902 f1score_val: 0.899   \n",
      "Epoch 32/300 - Loss_train: 1.027   loss_val: 1.114   accuracy_val: 0.890 f1score_val: 0.888   \n",
      "Epoch 33/300 - Loss_train: 1.022   loss_val: 1.105   accuracy_val: 0.899 f1score_val: 0.897   \n",
      "Epoch 34/300 - Loss_train: 0.994   loss_val: 1.087   accuracy_val: 0.907 f1score_val: 0.904   \n",
      "Epoch 35/300 - Loss_train: 0.983   loss_val: 1.073   accuracy_val: 0.896 f1score_val: 0.890   \n",
      "Epoch 36/300 - Loss_train: 0.971   loss_val: 1.056   accuracy_val: 0.896 f1score_val: 0.894   \n",
      "Epoch 37/300 - Loss_train: 0.961   loss_val: 1.047   accuracy_val: 0.899 f1score_val: 0.896   \n",
      "Epoch 38/300 - Loss_train: 0.954   loss_val: 1.025   accuracy_val: 0.927 f1score_val: 0.924   \n",
      "Epoch 39/300 - Loss_train: 0.931   loss_val: 1.027   accuracy_val: 0.910 f1score_val: 0.908   \n",
      "Epoch 40/300 - Loss_train: 0.913   loss_val: 1.026   accuracy_val: 0.913 f1score_val: 0.909   \n",
      "Epoch 41/300 - Loss_train: 0.903   loss_val: 1.009   accuracy_val: 0.888 f1score_val: 0.883   \n",
      "Epoch 42/300 - Loss_train: 0.884   loss_val: 1.006   accuracy_val: 0.916 f1score_val: 0.913   \n",
      "Epoch 43/300 - Loss_train: 0.872   loss_val: 0.986   accuracy_val: 0.924 f1score_val: 0.921   \n",
      "Epoch 44/300 - Loss_train: 0.857   loss_val: 0.976   accuracy_val: 0.916 f1score_val: 0.911   \n",
      "Epoch 45/300 - Loss_train: 0.855   loss_val: 0.983   accuracy_val: 0.919 f1score_val: 0.915   \n",
      "Epoch 46/300 - Loss_train: 0.839   loss_val: 0.953   accuracy_val: 0.924 f1score_val: 0.921   \n",
      "Epoch 47/300 - Loss_train: 0.826   loss_val: 0.954   accuracy_val: 0.935 f1score_val: 0.933   \n",
      "Epoch 48/300 - Loss_train: 0.809   loss_val: 0.922   accuracy_val: 0.941 f1score_val: 0.940   \n",
      "Epoch 49/300 - Loss_train: 0.798   loss_val: 0.928   accuracy_val: 0.919 f1score_val: 0.916   \n",
      "Epoch 50/300 - Loss_train: 0.790   loss_val: 0.908   accuracy_val: 0.949 f1score_val: 0.949   \n",
      "Epoch 51/300 - Loss_train: 0.782   loss_val: 0.903   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 52/300 - Loss_train: 0.768   loss_val: 0.891   accuracy_val: 0.930 f1score_val: 0.927   \n",
      "Epoch 53/300 - Loss_train: 0.760   loss_val: 0.880   accuracy_val: 0.924 f1score_val: 0.922   \n",
      "Epoch 54/300 - Loss_train: 0.746   loss_val: 0.863   accuracy_val: 0.941 f1score_val: 0.939   \n",
      "Epoch 55/300 - Loss_train: 0.729   loss_val: 0.866   accuracy_val: 0.933 f1score_val: 0.930   \n",
      "Epoch 56/300 - Loss_train: 0.725   loss_val: 0.864   accuracy_val: 0.938 f1score_val: 0.937   \n",
      "Epoch 57/300 - Loss_train: 0.718   loss_val: 0.843   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 58/300 - Loss_train: 0.700   loss_val: 0.842   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 59/300 - Loss_train: 0.697   loss_val: 0.831   accuracy_val: 0.944 f1score_val: 0.942   \n",
      "Epoch 60/300 - Loss_train: 0.677   loss_val: 0.816   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 61/300 - Loss_train: 0.679   loss_val: 0.804   accuracy_val: 0.941 f1score_val: 0.939   \n",
      "Epoch 62/300 - Loss_train: 0.662   loss_val: 0.788   accuracy_val: 0.949 f1score_val: 0.947   \n",
      "Epoch 63/300 - Loss_train: 0.653   loss_val: 0.784   accuracy_val: 0.952 f1score_val: 0.951   \n",
      "Epoch 64/300 - Loss_train: 0.641   loss_val: 0.797   accuracy_val: 0.941 f1score_val: 0.939   \n",
      "Epoch 65/300 - Loss_train: 0.641   loss_val: 0.782   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 66/300 - Loss_train: 0.627   loss_val: 0.767   accuracy_val: 0.947 f1score_val: 0.945   \n",
      "Epoch 67/300 - Loss_train: 0.614   loss_val: 0.746   accuracy_val: 0.938 f1score_val: 0.935   \n",
      "Epoch 68/300 - Loss_train: 0.618   loss_val: 0.753   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 69/300 - Loss_train: 0.601   loss_val: 0.740   accuracy_val: 0.941 f1score_val: 0.940   \n",
      "Epoch 70/300 - Loss_train: 0.578   loss_val: 0.732   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 71/300 - Loss_train: 0.577   loss_val: 0.745   accuracy_val: 0.949 f1score_val: 0.947   \n",
      "Epoch 72/300 - Loss_train: 0.567   loss_val: 0.731   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 73/300 - Loss_train: 0.561   loss_val: 0.718   accuracy_val: 0.949 f1score_val: 0.948   \n",
      "Epoch 74/300 - Loss_train: 0.562   loss_val: 0.718   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 75/300 - Loss_train: 0.543   loss_val: 0.718   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 76/300 - Loss_train: 0.535   loss_val: 0.693   accuracy_val: 0.938 f1score_val: 0.936   \n",
      "Epoch 77/300 - Loss_train: 0.534   loss_val: 0.689   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 78/300 - Loss_train: 0.519   loss_val: 0.669   accuracy_val: 0.941 f1score_val: 0.939   \n",
      "Epoch 79/300 - Loss_train: 0.515   loss_val: 0.666   accuracy_val: 0.949 f1score_val: 0.947   \n",
      "Epoch 80/300 - Loss_train: 0.503   loss_val: 0.654   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 81/300 - Loss_train: 0.500   loss_val: 0.654   accuracy_val: 0.947 f1score_val: 0.944   \n",
      "Epoch 82/300 - Loss_train: 0.489   loss_val: 0.645   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 83/300 - Loss_train: 0.478   loss_val: 0.649   accuracy_val: 0.947 f1score_val: 0.944   \n",
      "Epoch 84/300 - Loss_train: 0.471   loss_val: 0.630   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 85/300 - Loss_train: 0.462   loss_val: 0.603   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 86/300 - Loss_train: 0.456   loss_val: 0.614   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 87/300 - Loss_train: 0.462   loss_val: 0.607   accuracy_val: 0.963 f1score_val: 0.961   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300 - Loss_train: 0.453   loss_val: 0.601   accuracy_val: 0.947 f1score_val: 0.945   \n",
      "Epoch 89/300 - Loss_train: 0.439   loss_val: 0.598   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 90/300 - Loss_train: 0.434   loss_val: 0.588   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 91/300 - Loss_train: 0.423   loss_val: 0.594   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 92/300 - Loss_train: 0.421   loss_val: 0.577   accuracy_val: 0.949 f1score_val: 0.947   \n",
      "Epoch 93/300 - Loss_train: 0.409   loss_val: 0.563   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 94/300 - Loss_train: 0.415   loss_val: 0.560   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 95/300 - Loss_train: 0.397   loss_val: 0.568   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 96/300 - Loss_train: 0.396   loss_val: 0.568   accuracy_val: 0.952 f1score_val: 0.951   \n",
      "Epoch 97/300 - Loss_train: 0.388   loss_val: 0.548   accuracy_val: 0.961 f1score_val: 0.960   \n",
      "Epoch 98/300 - Loss_train: 0.388   loss_val: 0.558   accuracy_val: 0.955 f1score_val: 0.954   \n",
      "Epoch 99/300 - Loss_train: 0.384   loss_val: 0.539   accuracy_val: 0.955 f1score_val: 0.952   \n",
      "Epoch 100/300 - Loss_train: 0.366   loss_val: 0.525   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 101/300 - Loss_train: 0.365   loss_val: 0.544   accuracy_val: 0.947 f1score_val: 0.944   \n",
      "Epoch 102/300 - Loss_train: 0.359   loss_val: 0.507   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 103/300 - Loss_train: 0.348   loss_val: 0.498   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 104/300 - Loss_train: 0.342   loss_val: 0.508   accuracy_val: 0.949 f1score_val: 0.947   \n",
      "Epoch 105/300 - Loss_train: 0.346   loss_val: 0.511   accuracy_val: 0.961 f1score_val: 0.960   \n",
      "Epoch 106/300 - Loss_train: 0.335   loss_val: 0.495   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 107/300 - Loss_train: 0.329   loss_val: 0.501   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 108/300 - Loss_train: 0.322   loss_val: 0.489   accuracy_val: 0.944 f1score_val: 0.941   \n",
      "Epoch 109/300 - Loss_train: 0.319   loss_val: 0.495   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 110/300 - Loss_train: 0.312   loss_val: 0.468   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 111/300 - Loss_train: 0.304   loss_val: 0.474   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 112/300 - Loss_train: 0.303   loss_val: 0.470   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 113/300 - Loss_train: 0.295   loss_val: 0.460   accuracy_val: 0.952 f1score_val: 0.951   \n",
      "Epoch 114/300 - Loss_train: 0.299   loss_val: 0.472   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 115/300 - Loss_train: 0.288   loss_val: 0.439   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 116/300 - Loss_train: 0.287   loss_val: 0.446   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 117/300 - Loss_train: 0.281   loss_val: 0.447   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 118/300 - Loss_train: 0.275   loss_val: 0.446   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 119/300 - Loss_train: 0.273   loss_val: 0.435   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 120/300 - Loss_train: 0.269   loss_val: 0.425   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 121/300 - Loss_train: 0.271   loss_val: 0.415   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 122/300 - Loss_train: 0.262   loss_val: 0.412   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 123/300 - Loss_train: 0.255   loss_val: 0.406   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 124/300 - Loss_train: 0.250   loss_val: 0.415   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 125/300 - Loss_train: 0.243   loss_val: 0.416   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 126/300 - Loss_train: 0.245   loss_val: 0.414   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 127/300 - Loss_train: 0.237   loss_val: 0.393   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 128/300 - Loss_train: 0.236   loss_val: 0.395   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 129/300 - Loss_train: 0.233   loss_val: 0.386   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 130/300 - Loss_train: 0.224   loss_val: 0.377   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 131/300 - Loss_train: 0.225   loss_val: 0.387   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 132/300 - Loss_train: 0.234   loss_val: 0.395   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 133/300 - Loss_train: 0.214   loss_val: 0.373   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 134/300 - Loss_train: 0.221   loss_val: 0.393   accuracy_val: 0.952 f1score_val: 0.949   \n",
      "Epoch 135/300 - Loss_train: 0.214   loss_val: 0.374   accuracy_val: 0.949 f1score_val: 0.947   \n",
      "Epoch 136/300 - Loss_train: 0.210   loss_val: 0.366   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 137/300 - Loss_train: 0.202   loss_val: 0.355   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 138/300 - Loss_train: 0.203   loss_val: 0.384   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 139/300 - Loss_train: 0.194   loss_val: 0.371   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 140/300 - Loss_train: 0.195   loss_val: 0.354   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 141/300 - Loss_train: 0.195   loss_val: 0.369   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 142/300 - Loss_train: 0.188   loss_val: 0.351   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 143/300 - Loss_train: 0.187   loss_val: 0.363   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 144/300 - Loss_train: 0.187   loss_val: 0.346   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 145/300 - Loss_train: 0.183   loss_val: 0.337   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 146/300 - Loss_train: 0.182   loss_val: 0.345   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 147/300 - Loss_train: 0.180   loss_val: 0.349   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 148/300 - Loss_train: 0.171   loss_val: 0.340   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 149/300 - Loss_train: 0.172   loss_val: 0.338   accuracy_val: 0.952 f1score_val: 0.951   \n",
      "Epoch 150/300 - Loss_train: 0.171   loss_val: 0.336   accuracy_val: 0.963 f1score_val: 0.963   \n",
      "Epoch 151/300 - Loss_train: 0.162   loss_val: 0.318   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 152/300 - Loss_train: 0.166   loss_val: 0.323   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 153/300 - Loss_train: 0.161   loss_val: 0.324   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 154/300 - Loss_train: 0.160   loss_val: 0.304   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 155/300 - Loss_train: 0.155   loss_val: 0.314   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 156/300 - Loss_train: 0.153   loss_val: 0.334   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 157/300 - Loss_train: 0.148   loss_val: 0.311   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 158/300 - Loss_train: 0.149   loss_val: 0.319   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 159/300 - Loss_train: 0.149   loss_val: 0.302   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 160/300 - Loss_train: 0.153   loss_val: 0.298   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 161/300 - Loss_train: 0.149   loss_val: 0.296   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 162/300 - Loss_train: 0.143   loss_val: 0.286   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 163/300 - Loss_train: 0.144   loss_val: 0.299   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 164/300 - Loss_train: 0.141   loss_val: 0.299   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 165/300 - Loss_train: 0.138   loss_val: 0.275   accuracy_val: 0.980 f1score_val: 0.979   \n",
      "Epoch 166/300 - Loss_train: 0.134   loss_val: 0.282   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 167/300 - Loss_train: 0.135   loss_val: 0.293   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 168/300 - Loss_train: 0.132   loss_val: 0.293   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 169/300 - Loss_train: 0.126   loss_val: 0.291   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 170/300 - Loss_train: 0.127   loss_val: 0.261   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 171/300 - Loss_train: 0.131   loss_val: 0.276   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 172/300 - Loss_train: 0.123   loss_val: 0.268   accuracy_val: 0.961 f1score_val: 0.960   \n",
      "Epoch 173/300 - Loss_train: 0.126   loss_val: 0.282   accuracy_val: 0.963 f1score_val: 0.962   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/300 - Loss_train: 0.120   loss_val: 0.263   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 175/300 - Loss_train: 0.119   loss_val: 0.285   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 176/300 - Loss_train: 0.119   loss_val: 0.276   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 177/300 - Loss_train: 0.116   loss_val: 0.256   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 178/300 - Loss_train: 0.115   loss_val: 0.259   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 179/300 - Loss_train: 0.113   loss_val: 0.266   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 180/300 - Loss_train: 0.110   loss_val: 0.268   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 181/300 - Loss_train: 0.110   loss_val: 0.256   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 182/300 - Loss_train: 0.111   loss_val: 0.247   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 183/300 - Loss_train: 0.113   loss_val: 0.269   accuracy_val: 0.961 f1score_val: 0.960   \n",
      "Epoch 184/300 - Loss_train: 0.103   loss_val: 0.251   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 185/300 - Loss_train: 0.105   loss_val: 0.241   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 186/300 - Loss_train: 0.106   loss_val: 0.259   accuracy_val: 0.966 f1score_val: 0.966   \n",
      "Epoch 187/300 - Loss_train: 0.106   loss_val: 0.274   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 188/300 - Loss_train: 0.098   loss_val: 0.257   accuracy_val: 0.955 f1score_val: 0.953   \n",
      "Epoch 189/300 - Loss_train: 0.103   loss_val: 0.250   accuracy_val: 0.958 f1score_val: 0.955   \n",
      "Epoch 190/300 - Loss_train: 0.100   loss_val: 0.247   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 191/300 - Loss_train: 0.099   loss_val: 0.243   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 192/300 - Loss_train: 0.091   loss_val: 0.245   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 193/300 - Loss_train: 0.092   loss_val: 0.248   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 194/300 - Loss_train: 0.097   loss_val: 0.242   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 195/300 - Loss_train: 0.094   loss_val: 0.225   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 196/300 - Loss_train: 0.089   loss_val: 0.233   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 197/300 - Loss_train: 0.094   loss_val: 0.235   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 198/300 - Loss_train: 0.092   loss_val: 0.225   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 199/300 - Loss_train: 0.084   loss_val: 0.233   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 200/300 - Loss_train: 0.087   loss_val: 0.215   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 201/300 - Loss_train: 0.088   loss_val: 0.237   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 202/300 - Loss_train: 0.084   loss_val: 0.225   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 203/300 - Loss_train: 0.082   loss_val: 0.239   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 204/300 - Loss_train: 0.083   loss_val: 0.207   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 205/300 - Loss_train: 0.083   loss_val: 0.221   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 206/300 - Loss_train: 0.079   loss_val: 0.224   accuracy_val: 0.975 f1score_val: 0.974   \n",
      "Epoch 207/300 - Loss_train: 0.077   loss_val: 0.212   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 208/300 - Loss_train: 0.079   loss_val: 0.228   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 209/300 - Loss_train: 0.078   loss_val: 0.217   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 210/300 - Loss_train: 0.077   loss_val: 0.210   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 211/300 - Loss_train: 0.076   loss_val: 0.208   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 212/300 - Loss_train: 0.075   loss_val: 0.215   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 213/300 - Loss_train: 0.075   loss_val: 0.209   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 214/300 - Loss_train: 0.075   loss_val: 0.221   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 215/300 - Loss_train: 0.072   loss_val: 0.211   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 216/300 - Loss_train: 0.069   loss_val: 0.236   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 217/300 - Loss_train: 0.069   loss_val: 0.200   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 218/300 - Loss_train: 0.068   loss_val: 0.219   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 219/300 - Loss_train: 0.067   loss_val: 0.205   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 220/300 - Loss_train: 0.070   loss_val: 0.207   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 221/300 - Loss_train: 0.070   loss_val: 0.211   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 222/300 - Loss_train: 0.065   loss_val: 0.206   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 223/300 - Loss_train: 0.068   loss_val: 0.197   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 224/300 - Loss_train: 0.064   loss_val: 0.221   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 225/300 - Loss_train: 0.065   loss_val: 0.207   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 226/300 - Loss_train: 0.065   loss_val: 0.213   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 227/300 - Loss_train: 0.065   loss_val: 0.200   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 228/300 - Loss_train: 0.065   loss_val: 0.180   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 229/300 - Loss_train: 0.059   loss_val: 0.200   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 230/300 - Loss_train: 0.061   loss_val: 0.195   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 231/300 - Loss_train: 0.060   loss_val: 0.188   accuracy_val: 0.961 f1score_val: 0.958   \n",
      "Epoch 232/300 - Loss_train: 0.061   loss_val: 0.196   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 233/300 - Loss_train: 0.057   loss_val: 0.207   accuracy_val: 0.958 f1score_val: 0.957   \n",
      "Epoch 234/300 - Loss_train: 0.058   loss_val: 0.196   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 235/300 - Loss_train: 0.061   loss_val: 0.198   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 236/300 - Loss_train: 0.058   loss_val: 0.194   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 237/300 - Loss_train: 0.057   loss_val: 0.191   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 238/300 - Loss_train: 0.058   loss_val: 0.182   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 239/300 - Loss_train: 0.056   loss_val: 0.170   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 240/300 - Loss_train: 0.056   loss_val: 0.176   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 241/300 - Loss_train: 0.054   loss_val: 0.182   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 242/300 - Loss_train: 0.054   loss_val: 0.197   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 243/300 - Loss_train: 0.055   loss_val: 0.205   accuracy_val: 0.975 f1score_val: 0.974   \n",
      "Epoch 244/300 - Loss_train: 0.053   loss_val: 0.185   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 245/300 - Loss_train: 0.052   loss_val: 0.182   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 246/300 - Loss_train: 0.052   loss_val: 0.201   accuracy_val: 0.955 f1score_val: 0.952   \n",
      "Epoch 247/300 - Loss_train: 0.053   loss_val: 0.193   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 248/300 - Loss_train: 0.052   loss_val: 0.194   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 249/300 - Loss_train: 0.050   loss_val: 0.169   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 250/300 - Loss_train: 0.053   loss_val: 0.190   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 251/300 - Loss_train: 0.048   loss_val: 0.179   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 252/300 - Loss_train: 0.046   loss_val: 0.179   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 253/300 - Loss_train: 0.048   loss_val: 0.185   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 254/300 - Loss_train: 0.048   loss_val: 0.185   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 255/300 - Loss_train: 0.048   loss_val: 0.178   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 256/300 - Loss_train: 0.048   loss_val: 0.175   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 257/300 - Loss_train: 0.046   loss_val: 0.163   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 258/300 - Loss_train: 0.046   loss_val: 0.183   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 259/300 - Loss_train: 0.048   loss_val: 0.168   accuracy_val: 0.972 f1score_val: 0.970   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/300 - Loss_train: 0.047   loss_val: 0.188   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 261/300 - Loss_train: 0.042   loss_val: 0.177   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 262/300 - Loss_train: 0.043   loss_val: 0.169   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 263/300 - Loss_train: 0.043   loss_val: 0.185   accuracy_val: 0.958 f1score_val: 0.956   \n",
      "Epoch 264/300 - Loss_train: 0.044   loss_val: 0.180   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 265/300 - Loss_train: 0.043   loss_val: 0.183   accuracy_val: 0.952 f1score_val: 0.950   \n",
      "Epoch 266/300 - Loss_train: 0.042   loss_val: 0.174   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 267/300 - Loss_train: 0.043   loss_val: 0.176   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 268/300 - Loss_train: 0.044   loss_val: 0.178   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 269/300 - Loss_train: 0.045   loss_val: 0.163   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 270/300 - Loss_train: 0.042   loss_val: 0.176   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 271/300 - Loss_train: 0.041   loss_val: 0.165   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 272/300 - Loss_train: 0.041   loss_val: 0.169   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 273/300 - Loss_train: 0.041   loss_val: 0.176   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 274/300 - Loss_train: 0.040   loss_val: 0.172   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 275/300 - Loss_train: 0.042   loss_val: 0.158   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 276/300 - Loss_train: 0.041   loss_val: 0.172   accuracy_val: 0.963 f1score_val: 0.962   \n",
      "Epoch 277/300 - Loss_train: 0.038   loss_val: 0.164   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 278/300 - Loss_train: 0.041   loss_val: 0.164   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 279/300 - Loss_train: 0.039   loss_val: 0.172   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 280/300 - Loss_train: 0.039   loss_val: 0.175   accuracy_val: 0.966 f1score_val: 0.965   \n",
      "Epoch 281/300 - Loss_train: 0.037   loss_val: 0.172   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 282/300 - Loss_train: 0.037   loss_val: 0.160   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 283/300 - Loss_train: 0.039   loss_val: 0.148   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 284/300 - Loss_train: 0.037   loss_val: 0.146   accuracy_val: 0.978 f1score_val: 0.977   \n",
      "Epoch 285/300 - Loss_train: 0.036   loss_val: 0.159   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 286/300 - Loss_train: 0.038   loss_val: 0.171   accuracy_val: 0.961 f1score_val: 0.959   \n",
      "Epoch 287/300 - Loss_train: 0.035   loss_val: 0.159   accuracy_val: 0.972 f1score_val: 0.971   \n",
      "Epoch 288/300 - Loss_train: 0.038   loss_val: 0.160   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 289/300 - Loss_train: 0.036   loss_val: 0.158   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 290/300 - Loss_train: 0.035   loss_val: 0.160   accuracy_val: 0.972 f1score_val: 0.970   \n",
      "Epoch 291/300 - Loss_train: 0.034   loss_val: 0.161   accuracy_val: 0.969 f1score_val: 0.967   \n",
      "Epoch 292/300 - Loss_train: 0.034   loss_val: 0.176   accuracy_val: 0.963 f1score_val: 0.961   \n",
      "Epoch 293/300 - Loss_train: 0.036   loss_val: 0.155   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 294/300 - Loss_train: 0.036   loss_val: 0.139   accuracy_val: 0.978 f1score_val: 0.976   \n",
      "Epoch 295/300 - Loss_train: 0.036   loss_val: 0.156   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 296/300 - Loss_train: 0.034   loss_val: 0.160   accuracy_val: 0.975 f1score_val: 0.973   \n",
      "Epoch 297/300 - Loss_train: 0.033   loss_val: 0.161   accuracy_val: 0.969 f1score_val: 0.968   \n",
      "Epoch 298/300 - Loss_train: 0.033   loss_val: 0.169   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 299/300 - Loss_train: 0.034   loss_val: 0.162   accuracy_val: 0.966 f1score_val: 0.964   \n",
      "Epoch 300/300 - Loss_train: 0.035   loss_val: 0.152   accuracy_val: 0.978 f1score_val: 0.976   \n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # the training routine is these 5 steps:\n",
    "    \n",
    "    # step 1. zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # step 2. compute the output\n",
    "    output = net(train_x_tensor)\n",
    "    \n",
    "    # step 3. compute the loss\n",
    "    loss = criterion(output, train_y_tensor)\n",
    "    \n",
    "    # step 4. use loss to produce gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # step 5. use optimizer to take gradient step\n",
    "    optimizer.step() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # validation set evaluation:\n",
    "        \n",
    "        # compute the output\n",
    "        output_val=net(val_x_tensor)\n",
    "        \n",
    "        # compute the loss\n",
    "        loss_val = criterion(output_val, val_y_tensor)\n",
    "        \n",
    "        # compute the prediction\n",
    "        predict_y= output_val.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # Use the \"evaluation_metrics\" function to find accuracy and f1 score\n",
    "        accuracy,f1score=evaluation_metrics(predict_y,val_y_tensor)\n",
    "        \n",
    "        print('Epoch %d/%d - Loss_train: %.3f   loss_val: %.3f   accuracy_val: %.3f f1score_val: %.3f   '% \\\n",
    "              (i + 1, epochs,loss.item(),loss_val.item(),accuracy,f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_tensor=torch.tensor(test_x.toarray()).float()\n",
    "test_y_tensor=torch.tensor(test_y)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test set evaluation:\n",
    "    \n",
    "    # compute the output\n",
    "    output_test=net(test_x_tensor)\n",
    "    \n",
    "    # compute the prediction\n",
    "    predict_test_y= output_test.data.max(1, keepdim=True)[1]\n",
    "    \n",
    "    # Use the \"evaluation_metrics\" function to find accuracy and f1 score\n",
    "    accuracy,f1score=evaluation_metrics(predict_test_y,test_y_tensor)\n",
    "    print('Accuracy_test: %.3f f1score_val: %.3f   '% (accuracy,f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
