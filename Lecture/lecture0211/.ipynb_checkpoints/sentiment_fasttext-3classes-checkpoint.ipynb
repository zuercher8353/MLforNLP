{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the polarity of a  word\n",
    "\n",
    "* use a polarity lexicon with positive, negative and neutral words\n",
    "* take 60% for training\n",
    "* use word embeddings as features\n",
    "\n",
    "* test traditional ML and MLP\n",
    "\n",
    "\n",
    "* result SVM (non-linear support vector machine) and MLP are on par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the fasttext embeddings \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def load_emb_from_file(filepath):\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0] \n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index, array of word embeddings\n",
    "\n",
    "widx,emb=load_emb_from_file(\"/home/klenner/Lehre/ml20/cc.de.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3656, 649, 1171, 373, 0.5339717282261742, 319)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# data of learning task: polarity lexicon for German\n",
    "polex=pd.read_csv(\"/home/klenner/Lehre/ml20/polexNeutNomen\",header=None,\n",
    "                  index_col=[0,1],usecols=[0,1],names=['lemma', 'pol'])\n",
    "\n",
    "#polex=pd.read_csv(\"/home/klenner/applications/jupyter/rnn-notebook/word_majority_label_ag.tsv\",header=None,\n",
    "#                  index_col=[0,1],usecols=[0,1],names=['lemma', 'pol'])\n",
    "\n",
    "ids=[]     # gather all embedding indices\n",
    "index={}   # map index to polarity\n",
    "oov=0      # out of vocabolary counter\n",
    "\n",
    "for (l,p),_ in polex.iterrows():  # (lemma,polarity) pairs\n",
    "    try:\n",
    "        id=widx[l]  \n",
    "        if p=='POS' or p=='PRO':\n",
    "            index[id]=1     # id is the word2vec index of lemma l\n",
    "            ids.append(id)  # all ids for data split below\n",
    "        elif p=='NEG' or p=='CON':\n",
    "            index[id]=0\n",
    "            ids.append(id)\n",
    "        else:\n",
    "            index[id]=2\n",
    "            ids.append(id)\n",
    "    except:\n",
    "        oov+=1\n",
    "        pass\n",
    "\n",
    "np.random.shuffle(ids)                    # random modifies ids directly\n",
    "noun=[(id,index[id]) for id in ids]       # create input pairs: (word2vecID,polarity)\n",
    "\n",
    "corpus_len=len(ids)\n",
    "trainsplit= int(corpus_len*0.6)\n",
    "                \n",
    "# split in train and test\n",
    "train=noun[:trainsplit]\n",
    "test=noun[trainsplit+1:]\n",
    "\n",
    "\n",
    "# what is the baseline in a majority voting setting\n",
    "pos=[1 for l,p in train if p == 1]\n",
    "neg=[1 for l,p in train if p == 0]\n",
    "neu=[1 for l,p in train if p == 2]\n",
    "\n",
    "a,b,c =len(pos),len(neg),len(neu)   # \n",
    "\n",
    "baseline = b/(a+b+c)    # Polex b, Anne c\n",
    "\n",
    "len(noun),a,b,c,baseline,oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7113543091655267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.78516624, 0.62632696, 0.62679426]),\n",
       " array([0.77820025, 0.65121413, 0.59545455]),\n",
       " array([0.78166773, 0.63852814, 0.61072261]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# create input for sklearn algorithms\n",
    "X_train = [emb[index] for (index,_) in train]\n",
    "y_train = [label for (_,label) in train]\n",
    "\n",
    "X_test = [emb[index] for (index,_) in test]\n",
    "y_test =  [label for (_,label) in test]\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "             neg     pos        neut\n",
    "prec: (array([0.75745785, 0.58719647, 0.60504202]),\n",
    "\n",
    "~rec: array([0.7664042 , 0.59375   , 0.57142857]),\n",
    "\n",
    "~ ~f1: array([0.76190476, 0.59045505, 0.5877551 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9151846785225718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.91716687, 0.91606715, 0.90566038]),\n",
       " array([0.96831432, 0.84326711, 0.87272727]),\n",
       " array([0.94204686, 0.87816092, 0.88888889]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(tol=1e-3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9138166894664843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.92597087, 0.87692308, 0.95081967]),\n",
       " array([0.96704689, 0.8807947 , 0.79090909]),\n",
       " array([0.94606324, 0.87885463, 0.86352357]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver= 'lbfgs', max_iter=1000,random_state=0,multi_class='multinomial')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The only difference between Perceptron and Multinomial Logistic Regression: softmax versus step function!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8454172366621067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.882494  , 0.76254826, 0.95454545]),\n",
       " array([0.93282636, 0.87196468, 0.47727273]),\n",
       " array([0.90696242, 0.81359423, 0.63636364]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=neigh.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9076607387140903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.93014706, 0.85327314, 0.93596059]),\n",
       " array([0.95712484, 0.8852459 , 0.78512397]),\n",
       " array([0.94344313, 0.86896552, 0.85393258]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf2 = svm.SVC(kernel='linear', C=1.0, random_state=0)\n",
    "\n",
    "clf2.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=clf2.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908344733242134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.92892157, 0.86175115, 0.9245283 ]),\n",
       " array([0.95586381, 0.87587822, 0.80991736]),\n",
       " array([0.94220012, 0.86875726, 0.86343612]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf4 = svm.SVC(kernel='rbf', random_state=0, gamma=0.10, C=10.0)\n",
    "\n",
    "clf4.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=clf4.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94132653 0.85487528 0.89451477] [0.93064313 0.88290398 0.87603306] [0.93595434 0.86866359 0.88517745]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9076607387140903"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation='relu',\n",
    "                    hidden_layer_sizes=(300,10), random_state=1,validation_fraction=0.2,early_stopping=False)\n",
    "                  \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None))\n",
    "\n",
    "accuracy_score(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "#sgd=SGDClassifier(random_state=42, max_iter=5)\n",
    "sgd=SGDClassifier(random_state=42,loss='log', alpha=0.01,max_iter=5)\n",
    "\n",
    "sgd.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=sgd.predict(X_test)\n",
    "\n",
    "print(precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None))\n",
    "accuracy_score(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    loss= ['hinge', 'log', 'modified_huber','squared_hinge', 'perceptron']\n",
    "    alpha=[0.5,0.1,0.01,0.001,0.0001]\n",
    "    maxiter=[1,4,5,10,11,12,15,20]\n",
    "    param_grid = {'loss': loss,'alpha':alpha,'max_iter':maxiter}\n",
    "    grid_search = GridSearchCV(sgd, param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "p=svc_param_selection(X_train,y_train,5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=SGDClassifier(random_state=42,loss='hinge', alpha=0.0001,max_iter=10)\n",
    "\n",
    "sgd.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=sgd.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    activation= ['tanh','relu']\n",
    "    alpha=[0.5,0.1,0.01,0.001,0.0001]\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    "    early_stopping=[False,True]\n",
    "    param_grid = {'activation': activation,'alpha':alpha,'solver':solver,'early_stopping':early_stopping}\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "p=svc_param_selection(X_train,y_train,5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    hidden_layer_sizes=[(200,10),(300,10),(200,50),(300,100),(200,100)]\n",
    "    activation= ['relu']\n",
    "    solver=['adam']\n",
    "    alpha=[0.1]\n",
    "    early_stopping=[True]\n",
    "    param_grid = {'hidden_layer_sizes':hidden_layer_sizes,'activation': activation,'alpha':alpha,'solver':solver,'early_stopping':early_stopping}\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "p=svc_param_selection(X_train,y_train,5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93316832 0.86111111 0.92342342] [0.95081967 0.87119438 0.84710744] [0.94191131 0.8661234  0.88362069]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9103967168262654"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the Winner is MLP (learn_rate of 0.1 is worse)\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation='relu',\n",
    "                    hidden_layer_sizes=(300,10), random_state=1,validation_fraction=0.2,early_stopping=True)\n",
    "                  \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None))\n",
    "\n",
    "accuracy_score(y_test,y_test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
