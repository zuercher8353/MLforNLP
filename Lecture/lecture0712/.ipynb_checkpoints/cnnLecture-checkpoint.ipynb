{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-zFqnzueH11",
    "outputId": "96ad3bf5-f80c-4d59-eb72-d301e124571a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBqK3m2ZiKRL"
   },
   "source": [
    "see: https://towardsdatascience.com/convolutional-neural-network-in-natural-language-processing-96d67f91275c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3U6GcRLeI63",
    "outputId": "1b00156c-5b99-414c-b21e-e52558b5223b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load imdb dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",num_words=None, skip_top=0, maxlen=None, seed=113, start_char=1, oov_char=2, index_from=3)\n",
    "vocab = tf.keras.datasets.imdb.get_word_index(path='imdb_word_index.json')\n",
    "\n",
    "# each text is a list of integers\n",
    "orig=x_train\n",
    "\n",
    "# Split the train set into train and validation set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state=17)\n",
    "\n",
    "# Training batch size\n",
    "batch_size = 50\n",
    "\n",
    "# Put x into tensors\n",
    "x_train = [torch.tensor(x) for x in x_train]\n",
    "# Add zeros at the end of each word vector to create vectors with equal size\n",
    "X_train = nn.utils.rnn.pad_sequence(x_train, batch_first=True, padding_value=0).long()\n",
    "padded=X_train\n",
    "# Split the data into batches\n",
    "X_train = X_train.view(-1, batch_size, X_train.shape[1])\n",
    "\n",
    "# Apply the same length of X_train on X_val and X_test\n",
    "len_voc = int((X_train.max()+1).item())\n",
    "\n",
    "x_val = [torch.tensor(x) for x in x_val]\n",
    "X_val = nn.utils.rnn.pad_sequence(x_val, batch_first=True, padding_value=0).long()\n",
    "X_val = X_val.view(-1, batch_size, X_val.shape[1])\n",
    "\n",
    "x_test = [torch.tensor(x) for x in x_test]\n",
    "X_test = nn.utils.rnn.pad_sequence(x_test, batch_first=True, padding_value=0,).long()\n",
    "X_test  = X_test.view(-1, batch_size, X_test.shape[1])\n",
    "\n",
    "y_train = torch.tensor(y_train).view(-1, batch_size)\n",
    "y_val = torch.tensor(y_val)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7eQ1mdiQ31F",
    "outputId": "bc7dd9a1-6b5e-4b8f-bebf-2b09f0f1fb84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189,\n",
       " array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "        list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "        list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "        list([1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 15305, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 64317, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 33929, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 23005, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 87564, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 18435, 192, 5, 1219, 3890, 19, 20523, 217, 4122, 1710, 537, 20341, 1236, 5, 736, 10, 10, 61, 403, 9, 47289, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 18665, 594, 7, 5168, 94, 9096, 3987, 15242, 11, 28280, 4, 538, 7, 1795, 246, 56615, 9, 10161, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 10197, 19, 49, 7, 4, 1885, 13699, 1118, 25, 80, 126, 842, 10, 10, 47289, 18223, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 16376, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 25837, 21, 29, 9, 2841, 23, 4, 1010, 26747, 793, 6, 13699, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 16376, 8, 124, 4, 882, 4, 882, 496, 27, 33029, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 11120, 1311, 8, 4, 23643, 7, 31, 7, 29851, 91, 22793, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 11876, 1775, 3353, 12716, 1846, 4, 11286, 7, 154, 5, 4, 518, 53, 13243, 11286, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 18223, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 33058, 4, 22793, 10359, 9, 242, 4, 91, 1202, 11377, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 18223, 13, 188, 1076, 3222, 19, 4, 13465, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 18223, 13, 33195, 14, 280, 13, 219, 4, 52788, 431, 758, 859, 4, 953, 1052, 12283, 7, 5991, 5, 94, 40, 25, 238, 60, 35410, 4, 15812, 804, 27767, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 22148, 23, 12, 1685, 195, 25, 238, 60, 796, 13713, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574]),\n",
       "        list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 22016, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113]),\n",
       "        list([1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 7982, 1051, 43222, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 86588, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 15344, 10, 10]),\n",
       "        list([1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 10626, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 16393, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 71690, 4183, 17, 369, 37, 215, 1345, 143, 32677, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 26441, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 74170, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 33740, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 77842, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]),\n",
       "        list([1, 4, 14906, 716, 4, 65, 7, 4, 689, 4367, 6308, 2343, 4804, 28674, 84206, 5270, 32099, 2315, 71688, 12572, 24785, 43394, 4, 10993, 628, 7685, 37, 9, 150, 4, 9820, 4069, 11, 2909, 4, 16287, 847, 313, 6, 176, 63860, 9, 6202, 138, 9, 4434, 19, 4, 96, 183, 26, 4, 192, 15, 27, 5842, 799, 7101, 39455, 588, 84, 11, 4, 3231, 152, 339, 5206, 42, 4869, 30497, 6293, 345, 4804, 37377, 142, 43, 218, 208, 54, 29, 853, 659, 46, 4, 882, 183, 80, 115, 30, 4, 172, 174, 10, 10, 1001, 398, 1001, 1055, 526, 34, 3717, 68395, 5262, 63370, 17, 4, 6706, 1094, 871, 64, 85, 22, 2030, 1109, 38, 230, 9, 4, 4324, 20636, 251, 5056, 1034, 195, 301, 14, 16, 31, 7, 4, 46035, 8, 783, 48545, 33, 4, 2945, 103, 465, 16454, 42, 845, 45, 446, 11, 1895, 19, 184, 76, 32, 4, 5310, 207, 110, 13, 197, 4, 14906, 16, 601, 964, 2152, 595, 13, 258, 4, 1730, 66, 338, 55, 5312, 4, 550, 728, 65, 1196, 8, 1839, 61, 1546, 42, 8361, 61, 602, 120, 45, 7304, 6, 320, 786, 99, 196, 11100, 786, 5936, 4, 225, 4, 373, 1009, 33, 4, 130, 63, 69, 72, 1104, 46, 1292, 225, 14, 66, 194, 11871, 1703, 56, 8, 803, 1004, 6, 18763, 155, 11, 4, 14906, 3231, 45, 853, 2029, 8, 30, 6, 117, 430, 19, 6, 8941, 9, 15, 66, 424, 8, 2337, 178, 9, 15, 66, 424, 8, 1465, 178, 9, 15, 66, 142, 15, 9, 424, 8, 28, 178, 662, 44, 12, 17, 4, 130, 898, 1686, 9, 6, 5623, 267, 185, 430, 4, 118, 21486, 277, 15, 4, 1188, 100, 216, 56, 19, 4, 357, 114, 10399, 367, 45, 115, 93, 788, 121, 4, 14906, 79, 32, 68, 278, 39, 8, 818, 162, 4165, 237, 600, 7, 98, 306, 8, 157, 549, 628, 11, 6, 12370, 13, 824, 15, 4104, 76, 42, 138, 36, 774, 77, 1059, 159, 150, 4, 229, 497, 8, 1493, 11, 175, 251, 453, 19, 8651, 189, 12, 43, 127, 6, 394, 292, 7, 8253, 4, 107, 8, 4, 2826, 15, 1082, 1251, 9, 906, 42, 1134, 6, 66, 78, 22, 15, 13, 244, 2519, 8, 135, 233, 52, 44, 10, 10, 466, 112, 398, 526, 34, 4, 1572, 4413, 6706, 1094, 225, 57, 599, 133, 225, 6, 227, 7, 541, 4323, 6, 171, 139, 7, 539, 11890, 56, 11, 6, 3231, 21, 164, 25, 426, 81, 33, 344, 624, 19, 6, 4617, 7, 10373, 12958, 6, 5802, 4, 22, 9, 1082, 629, 237, 45, 188, 6, 55, 655, 707, 6371, 956, 225, 1456, 841, 42, 1310, 225, 6, 2493, 1467, 7722, 2828, 21, 4, 14906, 9, 364, 23, 4, 2228, 2407, 225, 24, 76, 133, 18, 4, 189, 2293, 10, 10, 814, 11, 53728, 11, 2642, 14, 47, 15, 682, 364, 352, 168, 44, 12, 45, 24, 913, 93, 21, 247, 2441, 4, 116, 34, 35, 1859, 8, 72, 177, 9, 164, 8, 901, 344, 44, 13, 191, 135, 13, 126, 421, 233, 18, 259, 10, 10, 4, 14906, 6847, 4, 14065, 3074, 7, 112, 199, 753, 357, 39, 63, 12, 115, 15222, 763, 8, 15, 35, 3282, 1523, 65, 57, 599, 6, 1916, 277, 1730, 37, 25, 92, 202, 6, 8848, 44, 25, 28, 6, 22, 15, 122, 24, 4171, 72, 33, 32]),\n",
       "        list([1, 43, 188, 46, 5, 566, 264, 51, 6, 530, 664, 14, 9, 1713, 81, 25, 1135, 46, 7, 6, 20, 750, 11, 141, 4299, 5, 15455, 4441, 102, 28, 413, 38, 120, 5533, 15, 4, 3974, 7, 5369, 142, 371, 318, 5, 955, 1713, 571, 25242, 24762, 122, 14, 8, 72, 54, 12, 86, 385, 46, 5, 14, 20, 9, 399, 8, 72, 150, 13, 161, 124, 6, 155, 44, 14, 159, 170, 83, 12, 5, 51, 6, 866, 48, 25, 842, 4, 1120, 25, 238, 79, 4, 547, 15, 14, 9, 31, 7, 148, 16126, 102, 44, 35, 480, 3823, 2380, 19, 120, 4, 350, 228, 5, 269, 8, 28, 178, 1314, 2347, 7, 51, 6, 87, 65, 12, 9, 979, 21, 95, 24, 3186, 178, 11, 40732, 14, 9, 24, 15, 20, 4, 84, 376, 4, 65, 14, 127, 141, 6, 52, 292, 7, 4751, 175, 561, 7, 68, 3866, 137, 75, 2541, 68, 182, 5, 235, 175, 333, 19, 98, 50, 9, 38, 76, 724, 4, 6750, 15, 166, 285, 36, 140, 143, 38, 76, 53, 3094, 1301, 4, 6991, 16, 82, 6, 87, 3578, 44, 2527, 7612, 5, 800, 4, 3033, 11, 35, 1728, 96, 21, 14, 22, 9, 76, 53, 7, 6, 406, 65, 13, 43, 219, 12, 639, 21, 13, 80, 140, 5, 135, 15, 14, 9, 31, 7, 4, 118, 3672, 13, 28, 126, 110]),\n",
       "        list([1, 14, 20, 47, 111, 439, 3445, 19, 12, 15, 166, 12, 216, 125, 40, 6, 364, 352, 707, 1187, 39, 294, 11, 22, 396, 13, 28, 8, 202, 12, 1109, 23, 94, 15201, 151, 111, 211, 469, 4, 20, 13, 258, 546, 1104, 7273, 12, 16, 38, 78, 33, 211, 15, 12, 16, 2849, 63, 93, 12, 6, 253, 106, 10, 10, 48, 335, 267, 18, 6, 364, 1242, 1179, 20, 19, 6, 1009, 7, 1987, 189, 5, 6, 8419, 7, 2723, 13209, 95, 1719, 6, 6035, 7, 3912, 7144, 49, 369, 120, 5, 28, 49, 253, 10, 10, 13, 1041, 19, 85, 795, 15, 4, 481, 9, 55, 78, 807, 9, 375, 8, 1167, 8, 794, 76, 7, 4, 58, 5, 4, 816, 9, 243, 7, 43, 50])],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcQMM5n0Tgt7",
    "outputId": "e2f35037-e7d2-42b7-f09e-d6db54b2cdd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[1][-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6Ah-W4r0Rq6",
    "outputId": "eb616686-250f-42cc-c6f2-936844eb5bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      " tensor([[[[-1.7570,  0.1387,  0.8104, -0.4214, -0.2930, -0.1288],\n",
      "          [-0.8535, -0.7205, -1.8799,  0.4950,  0.0681, -0.6686],\n",
      "          [ 0.9352,  1.8163, -0.2217, -0.4284, -2.2374,  0.3587],\n",
      "          [ 0.1709,  0.0409, -1.6565, -1.1400,  0.5945,  0.4165]]]]) \n",
      "output\n",
      " tensor([[[[-1.4295, -1.0601, -0.6959],\n",
      "          [-0.5698, -1.6404, -0.4477]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "# schematic example\n",
    "# in=1,out=1,kernel quadratic (2), stride quadratic\n",
    "# out will be 2 row, 3 column\n",
    "# 1 batch, 1 example, 4 rows, 6 col\n",
    "\n",
    "m = nn.Conv2d(1, 1, 2, stride=2)\n",
    "input = torch.randn(1, 1, 4, 6)\n",
    "output=m(input)\n",
    "print(\"input\\n\",input,\"\\noutput\\n\",m(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uV_AaKvtZahD",
    "outputId": "063aa94f-ee93-484b-ce2f-1e0d629a5258"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6959, -0.4477]]], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max(dim) returns the maximum of the vectors in dim\n",
    "output.max(3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BFp0LGaLedYo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create word embedding from scratch\n",
    "#embeddings = nn.Embedding(len_voc, 100)\n",
    "\n",
    "# Build CNN model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.embeddings = nn.Embedding(len_voc, 100)\n",
    "        self.cnn = nn.Conv2d(1, 100, (3, 100)) #convolutional layer\n",
    "        self.clf = nn.Linear(100, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add word embeddings\n",
    "        x = self.embeddings(x)\n",
    "        # Add an extra dimension for CNN\n",
    "        x = x.unsqueeze(1)\n",
    "        # Apply CNN\n",
    "        x = self.cnn(x)\n",
    "        # Choose the maximum value of each filter and delete the extra dimension\n",
    "        x = x.max(2)[0].squeeze(2)\n",
    "        # Choose the most important features for the classification\n",
    "        x = F.relu(x) \n",
    "        #  Apply linear nn for classification\n",
    "        x = self.clf(x)\n",
    "        # Return the probability of positive and negative\n",
    "        return F.softmax(x, 1)\n",
    "\n",
    "# Use GPU for the model      \n",
    "model = Model().cuda()\n",
    "# opmization function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# calculate the loss\n",
    "criterio  = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bk53kfXLenCQ",
    "outputId": "b370f996-abb7-46fb-9d74-4793aa0b1159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Batch: 0 \t Loss: 0.8031814694 \t F1_val: 0.6649725826\n",
      "Epoch: 0 \t Batch: 200 \t Loss: 0.5812191963 \t F1_val: 0.7729067930\n",
      "Epoch: 1 \t Batch: 0 \t Loss: 0.5200683475 \t F1_val: 0.8169947379\n",
      "Epoch: 1 \t Batch: 200 \t Loss: 0.4643588364 \t F1_val: 0.8335027445\n",
      "Epoch: 2 \t Batch: 0 \t Loss: 0.4420814216 \t F1_val: 0.8531007752\n",
      "Epoch: 2 \t Batch: 200 \t Loss: 0.4100077152 \t F1_val: 0.8535414166\n",
      "Epoch: 3 \t Batch: 0 \t Loss: 0.3954419196 \t F1_val: 0.8616476153\n",
      "Epoch: 3 \t Batch: 200 \t Loss: 0.3767266870 \t F1_val: 0.8611279563\n",
      "Epoch: 4 \t Batch: 0 \t Loss: 0.3669271469 \t F1_val: 0.8666285060\n",
      "Epoch: 4 \t Batch: 200 \t Loss: 0.3598365784 \t F1_val: 0.8663870581\n",
      "Epoch: 5 \t Batch: 0 \t Loss: 0.3572112620 \t F1_val: 0.8529516995\n",
      "Epoch: 5 \t Batch: 200 \t Loss: 0.3527189195 \t F1_val: 0.8122587968\n",
      "Epoch: 6 \t Batch: 0 \t Loss: 0.3433207273 \t F1_val: 0.8694280079\n",
      "Epoch: 6 \t Batch: 200 \t Loss: 0.3422545493 \t F1_val: 0.8502415459\n",
      "Epoch: 7 \t Batch: 0 \t Loss: 0.3315950036 \t F1_val: 0.8700724055\n",
      "Epoch: 7 \t Batch: 200 \t Loss: 0.3326136470 \t F1_val: 0.8549201009\n",
      "Epoch: 8 \t Batch: 0 \t Loss: 0.3274209499 \t F1_val: 0.8660251665\n",
      "Epoch: 8 \t Batch: 200 \t Loss: 0.3278634250 \t F1_val: 0.8714883443\n",
      "Epoch: 9 \t Batch: 0 \t Loss: 0.3244366050 \t F1_val: 0.8738912457\n",
      "Epoch: 9 \t Batch: 200 \t Loss: 0.3240360916 \t F1_val: 0.8654781199\n",
      "Epoch: 10 \t Batch: 0 \t Loss: 0.3228327036 \t F1_val: 0.8729411765\n",
      "Epoch: 10 \t Batch: 200 \t Loss: 0.3215073645 \t F1_val: 0.8668153254\n",
      "Epoch: 11 \t Batch: 0 \t Loss: 0.3212656379 \t F1_val: 0.8699427669\n",
      "Epoch: 11 \t Batch: 200 \t Loss: 0.3206817508 \t F1_val: 0.8649087221\n",
      "Epoch: 12 \t Batch: 0 \t Loss: 0.3199549615 \t F1_val: 0.8713577800\n",
      "Epoch: 12 \t Batch: 200 \t Loss: 0.3195847273 \t F1_val: 0.8699122107\n",
      "Epoch: 13 \t Batch: 0 \t Loss: 0.3193277717 \t F1_val: 0.8693910256\n",
      "Epoch: 13 \t Batch: 200 \t Loss: 0.3193886578 \t F1_val: 0.8725899424\n",
      "Epoch: 14 \t Batch: 0 \t Loss: 0.3187010884 \t F1_val: 0.8663123467\n",
      "Epoch: 14 \t Batch: 200 \t Loss: 0.3193951547 \t F1_val: 0.8740267518\n",
      "Epoch: 15 \t Batch: 0 \t Loss: 0.3181984425 \t F1_val: 0.8725745149\n",
      "Epoch: 15 \t Batch: 200 \t Loss: 0.3189303875 \t F1_val: 0.8731328421\n",
      "Epoch: 16 \t Batch: 0 \t Loss: 0.3178882897 \t F1_val: 0.8739002933\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Function for evaluating\n",
    "def get_f1(X, y_real):\n",
    "  y_pred = []\n",
    "  for x in X:\n",
    "      # Choose the value with higher probability\n",
    "      y_pred.append(model(x.cuda()).argmax(1).cpu().detach())\n",
    "  y_pred = torch.cat(y_pred)\n",
    "  return metrics.f1_score(y_true=y_real, y_pred=y_pred)\n",
    "\n",
    "# Training steps\n",
    "epochs = 20\n",
    "LOSS = []\n",
    "for e in range(epochs):\n",
    "    for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "        \n",
    "        # Delete the prvious values of the gradient\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        loss = criterio(y_pred, y)\n",
    "\n",
    "        # Compute the gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply the optimization method for one step\n",
    "        optimizer.step()\n",
    "        \n",
    "        LOSS.append(loss.item())\n",
    "        if i%200==0:\n",
    "            with torch.no_grad():\n",
    "                f1 = get_f1(X_val, y_val)\n",
    "            print('Epoch: %d \\t Batch: %d \\t Loss: %.10f \\t F1_val: %.10f'%(e,i, torch.tensor(LOSS[-100:]).mean(), f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "u-uqhdyue29A",
    "outputId": "7112d15b-7ccd-4f4f-997d-2eecc08dd2e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f720b665940>]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(LOSS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e52d1Ype-tZ",
    "outputId": "22342f27-f622-4e1c-ba44-b364281765aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_test: 0.87242\n"
     ]
    }
   ],
   "source": [
    "print(\"F1_test: %.5f\"%(get_f1(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goEyYCeviGQT"
   },
   "source": [
    "https://towardsdatascience.com/convolutional-neural-network-in-natural-language-processing-96d67f91275c"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cnnLecture.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
