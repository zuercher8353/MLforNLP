{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the polarity of a  word\n",
    "\n",
    "* use a polarity lexicon with positive, negative and neutral words\n",
    "* take 60% for training\n",
    "* use word embeddings as features\n",
    "\n",
    "* test traditional ML and MLP\n",
    "* result SVM (non-linear support vector machine) and MLP are on par\n",
    "\n",
    "* use grid search to optimize hyperparameter\n",
    "\n",
    "\n",
    "* t-test comparing 2 ML approaches\n",
    "\n",
    "\n",
    "\n",
    "* non-representative data harms\n",
    "    * we learn a model with little neutral words\n",
    "    * we test the model with twice as many neutral words\n",
    "    * depending on the approach, accuracy drops by 4%\n",
    "    \n",
    " \n",
    "**NOTE: each run produces other results, the best ML approach might thus vary (the description in the test might be wrong, then** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the fasttext embeddings \n",
    "\n",
    "#import torch\n",
    "import numpy as np\n",
    "\n",
    "def load_emb_from_file(filepath):\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0] \n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index, array of word embeddings\n",
    "\n",
    "widx,emb=load_emb_from_file(\"/home/klenner/Lehre/ml20/cc.de.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution train (pos,neg,neut) (0.3076203833567087, 0.5535296867695184, 0.1388499298737728)\n",
      "distribution test (pos,neg,neut) (0.31157894736842107, 0.5445614035087719, 0.14385964912280702)\n",
      "\n",
      "\n",
      "out of voc = 322 and additional neutrals = 699\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# data of learning task: polarity lexicon for German\n",
    "polex=pd.read_csv(\"/home/klenner/Lehre/ml20/polexNeutNomen\",header=None,\n",
    "                  index_col=[0,1],usecols=[0,1],names=['lemma', 'pol'])\n",
    "\n",
    "#polex=pd.read_csv(\"/home/klenner/applications/jupyter/rnn-notebook/word_majority_label_ag.tsv\",header=None,\n",
    "#                  index_col=[0,1],usecols=[0,1],names=['lemma', 'pol'])\n",
    "\n",
    "ids=[]     # gather all embedding indices\n",
    "index={}   # map index to polarity\n",
    "oov=0      # out of vocabolary counter\n",
    "number_neut=0\n",
    "index_neut=[]\n",
    "max_neut=500\n",
    "\n",
    "for (l,p),_ in polex.iterrows():  # (lemma,polarity) pairs\n",
    "    try:\n",
    "        id=widx[l]  \n",
    "        if p=='POS' or p=='PRO':\n",
    "            index[id]=1     # id is the word2vec index of lemma l\n",
    "            ids.append(id)  # all ids for data split below\n",
    "        elif p=='NEG' or p=='CON':\n",
    "            index[id]=0\n",
    "            ids.append(id)\n",
    "        else:\n",
    "            number_neut+=1\n",
    "            if number_neut < max_neut:\n",
    "                index[id]=2\n",
    "                ids.append(id)\n",
    "            else:\n",
    "                index_neut.append(id)  # held out split of neutral nouns\n",
    "    except:\n",
    "        oov+=1\n",
    "        pass\n",
    "\n",
    "np.random.shuffle(ids)                    # random modifies ids directly\n",
    "noun=[(id,index[id]) for id in ids]       # create input pairs: (word2vecID,polarity)\n",
    "\n",
    "corpus_len=len(ids)\n",
    "trainsplit= int(corpus_len*0.6)\n",
    "                \n",
    "# split in train and test\n",
    "train=noun[:trainsplit]\n",
    "test=noun[trainsplit+1:]\n",
    "\n",
    "def distribution(set):\n",
    "    pos=[1 for l,p in set if p == 1]\n",
    "    neg=[1 for l,p in set if p == 0]\n",
    "    neut=[1 for l,p in set if p == 2]\n",
    "    all=len(set)\n",
    "\n",
    "    return (len(pos)/all, len(neg)/all, len(neut)/all)\n",
    "\n",
    "\n",
    "print(\"distribution train (pos,neg,neut)\", distribution(train))\n",
    "print(\"distribution test (pos,neg,neut)\", distribution(test))\n",
    "\n",
    "print(\"\\n\\nout of voc =\",oov,\"and additional neutrals =\",len(index_neut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution train (pos,neg,neut) (0.3076203833567087, 0.5535296867695184, 0.1388499298737728)\n",
      "distribution augmentet test (pos,neg,neut) (0.20903954802259886, 0.3653483992467043, 0.4256120527306968)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# create input for sklearn algorithms\n",
    "X_train = [emb[index] for (index,_) in train]\n",
    "y_train = [label for (_,label) in train]\n",
    "\n",
    "# we add more neutral examples to the test set\n",
    "# we thereby simulate the situtation that our training set was not representive\n",
    "X_test_neut = [emb[index] for (index,_) in test]+[emb[index] for index in index_neut]\n",
    "y_test_neut =  [label for (_,label) in test]+[2 for index in index_neut]\n",
    "\n",
    "X_test = [emb[index] for (index,_) in test]\n",
    "y_test =  [label for (_,label) in test]\n",
    "\n",
    "def distribution_list(set):\n",
    "    pos=[1 for p in set if p == 1]\n",
    "    neg=[1 for p in set if p == 0]\n",
    "    neut=[1 for p in set if p == 2]\n",
    "    all=len(set)\n",
    "\n",
    "    return (len(pos)/all, len(neg)/all, len(neut)/all)\n",
    "\n",
    "print(\"distribution train (pos,neg,neut)\", distribution(train))\n",
    "print(\"distribution augmentet test (pos,neg,neut)\", distribution_list(y_test_neut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original neut\t 0.7108771929824561\n",
      "additional neut\t 0.6793785310734464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.7790404 , 0.62186788, 0.63402062]),\n",
       " array([0.79510309, 0.61486486, 0.6       ]),\n",
       " array([0.7869898 , 0.61834655, 0.61654135]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "# result of a model learned from a non-representative is worse \n",
    "\n",
    "# apply it to the test set that has the same distribution as the training set\n",
    "y_test_predict=clf.predict(X_test)\n",
    "print(\"original neut\\t\", accuracy_score(y_test,y_test_predict))\n",
    "\n",
    "y_test_predict_neut=clf.predict(X_test_neut)\n",
    "print(\"additional neut\\t\",accuracy_score(y_test_neut,y_test_predict_neut))\n",
    "\n",
    "\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output format\n",
    "\n",
    "             neg     pos        neut\n",
    "prec: (array([0.75745785, 0.58719647, 0.60504202]),\n",
    "\n",
    "~rec: array([0.7664042 , 0.59375   , 0.57142857]),\n",
    "\n",
    "~ ~f1: array([0.76190476, 0.59045505, 0.5877551 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=neigh.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=1000.0, solver= 'liblinear', random_state=0,multi_class='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "# result of a model learned from a non-representative is worse \n",
    "y_test_predict=clf.predict(X_test)\n",
    "print(accuracy_score(y_test,y_test_predict))\n",
    "\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n",
    "\n",
    "tp_dec=[int(y_test[i]==y_test_predict[i]) for i in range(0,len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888421052631579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(tol=1e-3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_test_predict))\n",
    "precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n",
    "\n",
    "# 1 if prediction is right, 0 otherwise\n",
    "# true positive dec\n",
    "tp_perceptron=[int(y_test[i]==y_test_predict[i]) for i in range(0,len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9143859649122807\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf2 = svm.SVC(kernel='linear', C=1.0, random_state=0)\n",
    "\n",
    "clf2.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=clf2.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_test_predict))\n",
    "# precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n",
    "\n",
    "# true positive svm\n",
    "tp_svm=[int(y_test[i]==y_test_predict[i]) for i in range(0,len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% of values are below 2.3289712732415597\n",
      "\n",
      " 15.309129340992792 is clearly higher than it; rejection of null hypothesis, i.e. svm is sign. better\n"
     ]
    }
   ],
   "source": [
    "# statistically significant differance between svm and decicison tree??\n",
    "#\n",
    "# t-test (one-sided, subtract lower from higher, thus look at the right side of the normal distribution)\n",
    "#\n",
    "# determine t_value from mean of differences/standard deviation\n",
    "# null hypothesis: no difference\n",
    "\n",
    "from scipy.stats import t\n",
    "# pairwise difference of svm and dec\n",
    "diff=np.array([tp_svm[i]-tp_dec[i] for i in range(0,len(y_test))])\n",
    "\n",
    "df=len(y_test)-1\n",
    "\n",
    "mean=np.mean(diff)\n",
    "std=np.std(diff,ddof=1)\n",
    "\n",
    "print(\"99% of values are below\",t.ppf(0.99,df-1)) \n",
    "\n",
    "diff = np.array(tp_svm)-np.array(tp_dec)\n",
    "\n",
    "t_val=mean/(std/np.sqrt(len(y_test)))\n",
    "\n",
    "print(\"\\n\",t_val,\"is clearly higher than it; rejection of null hypothesis, i.e. svm is sign. better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3XmYlMXV9/HvcWBYRInIaCKIgKKR4EJsUaMYjRuIAjGa4Pao4RHhBSERAQEFGUQRZNE4LqhZXBGXGJKouESNRo0MSkREIhJUCEYEAyjIWu8f1f3c3cMyPUxPVy+/z3XNZVX13XCcazhzd91Vp8w5h4iIFIfdQgcgIiLZo6QvIlJElPRFRIqIkr6ISBFR0hcRKSJK+iIiRURJX0SkiCjpi4gUESV9EZEiUi90AFU1b97ctW7dOnQYIiJ5Zc6cOV8458qquy7nkn7r1q2prKwMHYaISF4xs4/TuU7TOyIiRURJX0SkiCjpi4gUESV9EZEiklbSN7MuZrbQzBaZ2TU7ue4nZubMLJY0Njz+voVmdkYmghYRkV1T7eodMysBKoDTgKXAbDOb6Zx7v8p1ewCDgL8njbUHegHfA/YDXjCzg51zWzL3vyAiIulKZ8lmJ2CRc24xgJlNB3oA71e5bixwMzAkaawHMN05twH4l5ktiv95b9Q2cJGs2LQJFi+Gf/8bEqfM1a8PbdvCfvuBWdj4RGoonaTfAvg0qb8UOCb5AjP7PrC/c+7PZjakynvfrPLeFrsYq0jdW7MGZs2CP/4R/v53n/A3b97+tU2awCGHwMknQ/fucNxxUC/ntr6IpKj1T6iZ7QZMBi6txZ/RB+gD0KpVq9qGJFIzzsErr8CUKfDMM/7uPh1ffQVz5vivW26BvfeGCy+EX/wC2rSp25hFdlE6D3KXAfsn9VvGxxL2ADoAL5vZEuBYYGb8YW517wXAOTfNORdzzsXKyqrdRSySGc7BY4/B0Uf7u/WZM7ef8PffHzp39tecfDJ06gR77bXtdStXwm23wUEHwc9+Bv/4R93/P4jUUDp3+rOBdmbWBp+wewEXJF50zq0Gmif6ZvYycLVzrtLM1gMPm9lk/IPcdsBbmQtfZBfNmwf9+8Orr2772pFH+umaM8+EDh1g9923vcY5+OILeOstPxU0cyYsX+5f27oVZsyAxx+Hfv1g7Njt/5IQCaDaO33n3GZgADALWADMcM7NN7NyM+tezXvnAzPwD32fBfpr5Y4EtW4d/PKX0LFjasJv2BCuuAI++ADeeQfGjIFjjtl+wgf/ALesDLp1g7vugqVL/dTQqadG12zdChUVft7/wQejB8EiAZnLsR/EWCzmVHBN6sT778NPfwrz50dj9erBoEEwdCjss09m/p65c2HYMHjuudTxiy6CO+6APfbIzN8jksTM5jjnYtVdpx25Uvicg9/8BmKx1IR/8sl+3v2WWzKX8MFPDz37LDzxhH8ekPDgg3DUUf6XgkggSvpS2LZsgYED4ec/h/Xr/VjDhjBtGrz4IrRvXzd/rxmccw4sWOD/7oQPP/RLO3//+7r5e0WqoaQvhWv9ejj3XLj99mjs0ENh9my4/PLsbKzafXe47z544IHo+cA338BPfpIal0iWKOlLYVq5Ek45BZ56Kho791yf8Dt0yH48F13k1/MfdJDvOwdXXglDhugBr2SVkr4UnkTCfyOp2sdVV8Gjj+54NU42HHIIvP46HHtsNHbLLT75K/FLlijpS2FZtQpOOy3aGGUGU6fCpEmwWw78uJeV+WcJPXtGYxUVfhevEr9kQQ78KxDJkP/+F04/3a+zB5/wf/1rvyQzlzRu7HcC9+oVjd12GwwerMQvdU5JXwrDN9/4XbRz5kRj994Ll14aLKSdqlfPP9w977xobMoUuPHGcDFJUVDSl/y3dStccknqDttp01KXSuaievXgoYf8Sp6Ea6+F++8PF5MUPCV9yX9Dh/paNwkTJ/olmfmgfn14+GH/4Dmhd2944YVwMUlBU9KX/FZR4R/SJgwY4OfG80lpqd+9e9hhvr95s9/Y9d57YeOSgqSkL/nrlVdSH9L27OlX6uTjaVZNm8LTT0OL+BlDa9f6/58vvwwblxQcJX3JT59+6h+CbokXbY3F/Px4SUnYuGqjZUuf+BN7CT76yB/KskWFaSVzlPQl/yTKGKxY4ftlZfDkk34pZL47/HBfHC7hmWfg+uuDhSOFR0lf8s/Agb6cAvg7+8ceS61mme/OO8+XZk644QZ/SItIBijpS36ZPh3uuSfqT54MP/xhuHjqyrhxfqNZwmWX+SktkVpS0pf8sXgx9OkT9Xv18nVrClFJiV/KmfgEs2qVn9/fvDlsXJL30kr6ZtbFzBaa2SIzu2Y7r/c1s3lmNtfMXjOz9vHx1ma2Pj4+18zuyvT/gBSJTZvg/PP9qhaAtm3h7rvzc6VOuvbe2z+cTtQMevVVP9UjUgvVJn0zKwEqgK5Ae+D8RFJP8rBz7jDn3JHABGBy0msfOeeOjH/1zVTgUmSuu84fQg5+J+v06bDnnmFjyobOnVMf5I4dC3/9a7BwJP+lc6ffCVjknFvsnNsITAd6JF/gnFuT1N0dUNUoyZxXX4UJE6L+TTfB0UeHiyfbRoyAk07y7UTJicQnHpEaSifptwCSnyAtjY+lMLP+ZvYR/k5/YNJLbczsHTN7xcw61ypaKT5ffeWLpiWqT552mq+NX0xKSvz5unvt5ftLluTfrmPJGRl7kOucq3DOHQgMA66NDy8HWjnnOgJXAQ+b2Tafyc2sj5lVmlnlisTaaxHwdXUWL/btpk19qeRcqIufbS1a+JITCffc49fwi9RQOv96lgHJi6Bbxsd2ZDrQE8A5t8E5tzLengN8BBxc9Q3OuWnOuZhzLlZWVpZu7FLonnsO7rwz6v/qV37XarHq1csf+ZjQu7df1SNSA+kk/dlAOzNrY2alQC8gZaeImbVL6nYDPoyPl8UfBGNmbYF2wOJMBC4Fbs0an9QSfvxjf85sMTPzvwT32cf3ly/PvQNiJOdVm/Sdc5uBAcAsYAEwwzk338zKzax7/LIBZjbfzObip3EuiY+fCLwbH38c6Ouc062JVG/ECFi61LebN4e77irs5Znpat48dXPagw/CrFnh4pG8Yy7HjmeLxWKusrIydBgS0t/+5pcqJn42H3kk9WhBgQsu8N8XgAMO8GWYmzQJG5MEZWZznHOx6q4rwidiktM2bPAHoCQSfrdu8LOfhY0pF02dCs2a+fbHH8OoUWHjkbyhpC+55aabYMEC327SBO64Q9M627PPPv5M3YRbb402r4nshJK+5I6FC1MPBr/pJmjVKlw8ue7ii/2+BfCbtvr0UW0eqZaSvuQG56B/f19jB+DYY6Ffv7Ax5TozX3+oUSPf/8c//CcjkZ1Q0pfc8Oij8OKLvr3bbn61Tj6fgpUtbdr4ukQJ117rl3KK7ICSvoS3Zk1qaYUrr4QjjggXT74ZPBi++13fXrtWJRpkp5T0JbzRo6O70+98B8rLw8aTb0pLU0s0PPII/OUv4eKRnKakL2HNmwe33Rb1J00qjpLJmfajH/nzBhKSn4+IJFHSl3Cc82UEtm71/ZNP1ias2pg0CfbYw7c/+CD17l8kTklfwnnySXjpJd8uKfF3/FqTv+u+853Uh7rXXw+qWitVKOlLGOvXw9VXR/1+/aBDh3DxFIpBg6BdvP7h6tV+NY9IEiV9CWPSJH8YCPizYMeMCRpOwSgtTd2pe8898M474eKRnKOkL9m3bJnfbZswdmxUR0Zqr1s36NrVtxPPTXKssKKEo6Qv2TdyJKxb59uHH+7LB0hmTZniD5AHf8bw738fNh7JGUr6kl1vvw2/+13UnzJFO2/rwiGHwIABUX/oUNi4MVw8kjOU9CV7nEvdLXr22X59udSN666LDlP/6CMt4RRASV+yaeZMePll3y4pgQkTgoZT8Jo1S62zX14OK1eGi0dygpK+ZMemTX6KIaFfv6hejNSd//f/4KCDfPu//1WJC0kv6ZtZFzNbaGaLzOya7bze18zmmdlcM3vNzNonvTY8/r6FZnZGJoOXPHL33fDPf/p206a+3o7UvdLS1E9Ud9wBixaFi0eCqzbpm1kJUAF0BdoD5ycn9biHnXOHOeeOBCYAk+PvbQ/0Ar4HdAHuiP95UkzWrEm9wxwxwh/wLdnRs6c/cxj8ISsjR4aNR4JK506/E7DIObfYObcRmA70SL7AObcmqbs7kFgU3AOY7pzb4Jz7F7Ao/udJMbnllqgcQKtWMHBg2HiKjRlMnBj1Z8yA2bPDxSNBpZP0WwCfJvWXxsdSmFl/M/sIf6c/sCbvlQK2fLnffZswdiw0bBgunmJ1zDFw7rlRf8gQbdgqUhl7kOucq3DOHQgMA2pU8MPM+phZpZlVrlCBqMJy/fWpG7EuvDBoOEXtxhujDVuvvAJPPx02HgkinaS/DNg/qd8yPrYj04GeNXmvc26acy7mnIuVlZWlEZLkhQ8+gPvui/o336yNWCG1a5e6+3nYMNiyJVw8EkQ6SX820M7M2phZKf7B7MzkC8ysXVK3G/BhvD0T6GVmDcysDdAOeKv2YUteuPbaKKmccgqcocVbwY0aBU2a+Pb8+fDQQ2HjkayrNuk75zYDA4BZwAJghnNuvpmVm1n3+GUDzGy+mc0FrgIuib93PjADeB94FujvnNOtRTGYPRueeCLqjx+vWvm5YN99U0tajxoFGzaEi0eyzlyOPcyJxWKusrIydBhSW6eeCi++6NvnnedXjEhuWLsW2raFL77w/Vtv1YqqAmBmc5xzsequ045cybwXXogSfkmJX7EjuWOPPVLX6t9wg/9FIEVBSV8yyzkYPjzq//znvuKj5Ja+ff2eCfB7KJIPXpGCpqQvmfXkk5CYnmvYMLXgl+SOhg1TTyubOFHn6RYJJX3JnC1bUg/mHjAAWrYMF4/s3MUXQ/t4RZWvvvJLaqXgKelL5jz0ECxY4Nt77gnXbFObT3JJ1ectFRX+KEspaEr6khkbN6ZWzhw82B94Lrntxz+Go47y7W++8Q91paAp6Utm3HsvLFni23vvDb/4RdBwJE1mMG5c1L/3Xli8OFw8UueU9KX21q1LvUMcPtxP70h+OP10OPFE3968OfUBrxQcJX2pvTvu8NU0Afbbz5/WJPmj6t3+Aw/A+++Hi0fqlJK+1M7atb7EQsK110KjRuHikV1zwgnQtatvO+ero0pBUtKX2rn11uiw7datoXfvoOFILSSv5HnsMZg7N1wsUmeU9GXXffmlPxUrYdQofyar5KejjvJHKyZoY11BUtKXXTd5Mqxe7dvt2vnNPpLfysujaqh//CO8pUrohUZJX3bNF1/A1KlRf8yY6FQmyV+HHQY/+1nUT95hLQVBSV92zYQJfus+QIcOqYlC8tv118Nu8dTw3HPw6qtBw5HMUtKXmvvsM7j99qg/ZkyUJCT/HXJI6lTdddfpEPUCon+pUnPjx8P69b7dsaPfyi+FZdSo1EPUX3opbDySMUr6UjPLlsFdd0X95Ad/UjjatoXLLov6utsvGGklfTPrYmYLzWyRmW1TOtHMrjKz983sXTN70cwOSHpti5nNjX/NrPpeyTM33hidqdqpE3TrFjYeqTsjR0L9+r79+ut+fl/yXrVJ38xKgAqgK9AeON/M2le57B0g5pw7HHgcmJD02nrn3JHxr+5I/vr4Y7jnnqivu/zCdsABcPnlUV93+wUhnTv9TsAi59xi59xGYDrQI/kC59xLzrl18e6bgE7OKEQ33ACbNvn28cf7Ql1S2EaMgAYNfHv2bPjTn8LGI7WWTtJvAXya1F8aH9uR3sAzSf2GZlZpZm+aWc/tvcHM+sSvqVyhI9ty00cfwW9+E/V1l18cWrSAfv2i/qhRutvPcxl9kGtmFwExYGLS8AHOuRhwATDVzA6s+j7n3DTnXMw5FysrK8tkSJIpN9zgj0MEOOkk+NGPgoYjWTRsWFREb+5ceOqpsPFIraST9JcB+yf1W8bHUpjZqcBIoLtzbkNi3Dm3LP7fxcDLQMdaxCshfPgh3H9/1C8vDxeLZN+3vw39+0f90aNh69Zw8UitpJP0ZwPtzKyNmZUCvYCUVThm1hG4G5/wP08a38vMGsTbzYHjARXqzjfl5dE/8tNOg86dw8Yj2Td0KOy+u2/PmwdPPBE2Htll1SZ959xmYAAwC1gAzHDOzTezcjNLrMaZCDQBHquyNPNQoNLM/gG8BIx3zinp55MFC/yB5wk6Vak4lZXBwIFRf/ToaLpP8oq5HHsoE4vFXGVlZegwJKFXL3j0Ud/u2hWefjpsPBLOypXQpo0/OAfgwQfhwgvDxiT/x8zmxJ+f7pR25MqOzZsHM2ZEfd3lF7eqB96Xl/szdSWvKOnLjl1/fbQ8r3t3OProoOFIDrjqKmja1Lf/+c/UqT/JC0r6sn3vvANPPhn1dWaqAHzrWzB4cNQvL4827EleUNKX7Rs9Omqfc46vpikCMGgQNGvm24sXw+9+FzYeqRElfdnW7Nn+qDzwu241ly/J9twThgyJ+mPHwsaN4eKRGlHSl20lH4j905/6k7FEkg0Y4JdxAnzyCdx3X9h4JG1K+pLq9dfh2Wd9e7fdUqd5RBKaNPHlGRLGjYNvvgkXj6RNSV9SJR+EfcEFcOih4WKR3Navny/RAP5wnbvvDhuPpEVJXyIvvwx/+Ytvl5ToLl92rnFjX3o54aabYN26HV8vOUFJXzznUu/yL7kEDjooXDySHy6/HFrGj8/4z3+goiJsPFItJX3xnn8eXnvNt+vXT/0FILIjDRvCtddG/Ztvjso0SE5S0pdt7/J794bWrYOFI3nmssuin5eVK+HWW4OGIzunpC/+CLy33vLtBg38gdgi6SotTV3me8st8OWX4eKRnVLSL3Zbt6Z+PO/bN5qjFUnXxRfDwQf79urVMGlS2Hhkh5T0i93jj8O77/p248YwfHjYeCQ/1auXunN76lT4/PMdXy/BKOkXs82bUz+WDxwI++4bLh7Jb8m7t7/+2j/UlZyjpF/MHnoIFi707ar1VERqarfdfB2ehIoKv2lLckpaSd/MupjZQjNbZGbXbOf1q8zsfTN718xeNLMDkl67xMw+jH9dksngpRY2bkwtlzx4cFQ5UWRX9egBRx3l2xs2wA03hI1HtlFt0jezEqAC6Aq0B843s/ZVLnsHiDnnDgceBybE39sMGA0cA3QCRpvZXpkLX3bZvffCkiW+3axZ6olIIrvKLDXR33uvL78sOSOdO/1OwCLn3GLn3EZgOtAj+QLn3EvOucT+6zeBxPKPM4DnnXOrnHNfAs8DXTITuuyydetSP4YPH+6nd0Qy4YwzoHNn3968WQfw5Jh0kn4L4NOk/tL42I70Bp7ZxfdKNtx+O3z2mW/vtx/07x82HiksZnDjjVH/wQdh/vxw8UiKjD7INbOLgBgwsYbv62NmlWZWuWLFikyGJFWtXg3jx0f9666DRo3CxSOF6YQT4Mwzfdu51L0gElQ6SX8ZsH9Sv2V8LIWZnQqMBLo75zbU5L3OuWnOuZhzLlaWOJhB6sakSdFuybZtfckFkbqQPLf/1FPRrm8JKp2kPxtoZ2ZtzKwU6AXMTL7AzDoCd+MTfvKOjFnA6Wa2V/wB7unxMQnh889hypSoX17ui6uJ1IWOHf3a/YTkMswSTLVJ3zm3GRiAT9YLgBnOuflmVm5m3eOXTQSaAI+Z2Vwzmxl/7ypgLP4Xx2ygPD4mIYwbB1995dsdOkCvXmHjkcI3dqw/mwHgxRfhhRfCxiOYcy50DClisZirrKwMHUbh+de/4JBDYNMm3585E84+O2xMUhz69IF77vHto47y0zy7aV9oppnZHOdcrLrr9J0vFqNGRQn/+OPhrLPCxiPFY/RoX3cfYM4ceOKJsPEUOSX9YvDuu77kQsL48X5ZnUg2tGjh6zoljBwZ3YBI1inpF4MRI/yyOfB3+CecEDYeKT7DhkHTpr794Yfwm9+EjaeIKekXur/+Ff78Z9+uumlGJFuaNfOJP+H6630lTsk6Jf1C5lxq5cyLLoLDDgsXjxS3QYPgO9/x7eXLfc19yTol/UL2+OOpxyAm19sRybbGjf3ekISbbwbtwM86Jf1CtWlT6maYK6+EAw7Y8fUi2XDppXDoob69dq1uRAJQ0i9U06bBokW+vdde2g0puaFevdQTte68M/o5laxQ0i9Ea9emnlc6YoRP/CK54KyzUksv64Ykq5T0C9H48dFcaatWMGBA2HhEkpnBxKRCvI89Bm+8ES6eIqOkX2g+/RQmT47648ZFuyFFcsUxx6QWY7vqqmgvidQpJf1CM2IEfPONb8dicMEFYeMR2ZGbboLSUt9+802/2kzqnJJ+Iams9KcUJUyapMJWkrvatvWryhKGDfOHqUudUkYoFM7B4MFRv2dPOPHEcPGIpGPkSL9bF3wl2NtvDxtPEVDSLxRPPeVLLsC2y+JEctVee/kKsAljx8IXX4SLpwgo6ReCDRvg6qujfr9+cPDB4eIRqYl+/aBdO99evTr1l4BknJJ+IZg6FRYv9u1mzXwxK5F8UVrqnz8l3H03zJsXLp4Cp6Sf7z77LPUA6jFjojlSkXxx1llw2mm+vXUr/PKXWsJZR9JK+mbWxcwWmtkiM7tmO6+faGZvm9lmMzu3ymtb4ufm/t/ZuZJBI0dG5962bw99+4aNR2RXmMGUKann6c5UuqgL1SZ9MysBKoCuQHvgfDNrX+WyT4BLgYe380esd84dGf/qvp3XZVfNmZN6GMXkyf4hrkg++t73Um9aBg+O9pxIxqRzp98JWOScW+yc2whMB3okX+CcW+KcexfYWgcxyvZs3erLKyQ+AnfrBmecETYmkdoaMyaqE/XRR6m7yyUj0kn6LYBPk/pL42PpamhmlWb2ppn13N4FZtYnfk3lCtXXTs/99/tdjOAfhE2ZEjYekUzYe+/UcsvjxvnSIpIx2XiQe4BzLgZcAEw1swOrXuCcm+aciznnYmVlZVkIKc+tXp169NzgwdGSN5F8d8UVcPjhvr1uXepyZKm1dJL+MmD/pH7L+FhanHPL4v9dDLwMdKxBfLI9Y8bA55/7dosWKk0rhaVevdSduTNmwEsvhYunwKST9GcD7cysjZmVAr2AtB6rm9leZtYg3m4OHA+8v6vBCjB/Ptx2W9SfNAmaNAkXj0hd6Nw5tVjglVf60+Ck1qpN+s65zcAAYBawAJjhnJtvZuVm1h3AzI42s6XAecDdZjY//vZDgUoz+wfwEjDeOaekv6uc87sXt2zx/ZNOSi1PK1JIJk6Mbmjmz9dB6hliLsc2QMRiMVdZWRk6jNz029/CZZf5dr168M470KFD0JBE6tQtt8CQIb7duDEsWOAPBpJtmNmc+PPTndKO3HyxcmX0ww/+0AklfCl0gwZFP+fr1vm+1IqSfr4YPjyqPtiqlYpSSXGoXx/uuivqP/UU/OlP4eIpAEr6+eCNN+Cee6L+bbfB7ruHi0ckm44/Hn7+86g/YAB8/XW4ePKckn6u27gRLr886p99NvTosePrRQrRzTdHhQQ//liVZGtBST/XTZjgVy6Av7v/1a/CxiMSQvPm/qFuwuTJ8Pbb4eLJY0r6uWzhwtQt6TfcAAccEC4ekZAuvRR+9CPf3roV/vd/YfPmoCHlIyX9XLV1K/Tp46d3AI4+OvUQaZFiY+YPWGnY0PffeUdr93eBkn6uuvfe6MzbkhL/IDdRa1ykWB10EIweHfVHjfLVOCVtSvq56JNPUotMDRkCRxwRLh6RXDJ4cPTvYf166N3bfzKWtCjp5xrn/GqdtWt9/5BDtCZfJFn9+nDffdEn31degTvvDBtTHlHSzzW//jU895xvm/mTsRo1ChuTSK456ii4Junk1mHDYPHicPHkESX9XPLpp768QsJVV8Fxx4WLRySXXXedP2IR/GYtTfOkRUk/V2zd6n9o16zx/YMPTl2uKSKpGjTwRQgT0zwvv5xah1+2S0k/V1RUwPPP+7aZn+bRtI7IzsViMHRo1B82zFfilB1S0s8FH3yQ+oM7ZIivNyIi1Rs9Ojpe8Ztv4KKLov0tsg0l/dA2bfI/pN984/uHHw7l5WFjEsknDRrAgw9Caanvv/22pkZ3Qkk/tPJymDPHt0tL/Q9vgwZhYxLJN4cdBuPGRf0bb4TXXw8XTw5LK+mbWRczW2hmi8zsmu28fqKZvW1mm83s3CqvXWJmH8a/LslU4AXh5ZdTf1DHjfM/vCJSc7/8Jfzwh769das/Y/e//w0bUw6qNumbWQlQAXQF2gPnm1n7Kpd9AlwKPFzlvc2A0cAxQCdgtJntVfuwC8DKlX5aJ3Fc5ckn+x9aEdk1JSVw//3wrW/5/scf+/pVOXYkbGjp3Ol3AhY55xY75zYC04GUgu7OuSXOuXeBqotkzwCed86tcs59CTwPdMlA3PnNOX8oxLJlvr/33n5aR7V1RGqnVavUA4cee8yvhJP/k07SbwF8mtRfGh9LR23eW7gqKmDmzKj/29/CfvsFC0ekoJx7rr/DT7jySnj//XDx5JiceJBrZn3MrNLMKlesWBE6nLr11lupu24HDYKzzgoXj0ghmjIF2sdnodev978IvvoqbEw5Ip2kvwzYP6nfMj6WjrTe65yb5pyLOediZWVlaf7ReWjVKvjpT/0yTYCOHf0xcCKSWY0bw6OPRhscFyyAvn01v096SX820M7M2phZKdALmFnNexJmAaeb2V7xB7inx8eKz9at8D//4x8uATRtCo8/ruWZInWlQ4fU6psPPeQPYSly1SZ959xmYAA+WS8AZjjn5ptZuZl1BzCzo81sKXAecLeZzY+/dxUwFv+LYzZQHh8rPuPHw5//HPXvvx/atg0Xj0gxuOQSf6xiwqBBMHt2uHhygLkc+7gTi8VcZWVl6DAy6+mn/bx94ns9ZIg/8FxE6t769fCDH8Dcub7fsiVUVsK++4aNK8PMbI5zLlbddTnxILeg/fOffpNIIuGfeGLqhiwRqVuNGvmp1MT6/aVL/YPdIq3Po6Rfl9asgR49YPVq399/f79uuH79sHGJFJsDD4Tp02G3eMp77TU/1VOElPTrypYtcOGFvoImQMOG8NRTsM8+YeMSKVZ6K0P/AAAJqElEQVRnnAE33RT177rLfxUZJf26cvXV8Kc/Rf377oPvfz9cPCLin6f16hX1BwyIjictEkr6deGOO2Dq1Kg/dKif1xeRsMz8DdhRR/n+li1w3nnw3nth48oiJf1Me/ZZv+074ZxzUj9SikhYjRv7MigtW/r+mjV+dd1//hM2rixR0s+kykp/15A4nPnoo+GBB6KHRyKSG/bbz0+/Nmni+x9/DN26wdq1YePKAmWjTPnwQzjzzKi+R6tW/m6iceOwcYnI9h1xhC/VkLgpmzPHfzIv8KWcSvqZsHy5XxmQKBbXrJmf5vn2t8PGJSI7d+aZqSt4XnjB7+LdWrVKfOFQ0q+tVaugSxf41798v1Ej/7Hx0EPDxiUi6bn88tQzdadPh4EDC7Y4m5J+baxe7RP+u+/6fkmJ33x13HFh4xKRmhk5Evr3j/oVFTBsWEEmfiX9XfXVV/7BT3Lxpl//2o+JSH4xg1tvTV3DP3EiXH99sJDqipL+rvj6a+jeHf72t2jsrrt86WQRyU+JM3Z79ozGyssLrlaWkn5NrV0LXbvCSy9FY1OmwBVXhItJRDKjfn0/p98l6Sjva6/1d/wFMtWjpF8Tq1f7VTqvvhqN3XQT/OIX4WISkcxq0ACefBJOOSUaGzMGRowoiMSvpJ+uFSvg1FPhjTeisVtugWuuCReTiNSNRo3gj39MveMfP97f4OX5ck4l/XQsWQInnOB33Cb86lcweHCwkESkjjVq5Cvjnn12NHbbbXDxxXm9gUtJvzrz5sHxx/vDUMA/5Z82zVfnE5HC1qCBP4Dl3HOjsYcf9gs5Ervv80xaSd/MupjZQjNbZGbbzGeYWQMzezT++t/NrHV8vLWZrTezufGv/Cpe/eKL0Lkz/Pvfvl9a6tfhX3552LhEJHtKS/3D3b59o7FZs+Ckk6LckEeqTfpmVgJUAF2B9sD5Zta+ymW9gS+dcwcBU4Cbk177yDl3ZPyrL/li2jT/0DZx6tUee/jSCj/5Sdi4RCT7Skp8yfTkdftz5sAxx0Rn7+aJdO70OwGLnHOLnXMbgelAjyrX9AB+F28/DpxiZpa5MLNo82Y/V3/FFb7WNviKfK+8AiefHDY2EQnHDEaP9ntySkr82NKl/nnfH/4QNrYaSCfptwA+TeovjY9t9xrn3GZgNbB3/LU2ZvaOmb1iZp239xeYWR8zqzSzyhWJomUhfPGFf1o/eXI01rEjvPWW/6+IyBVXwNNPw557+v7XX/sNXaNH58XKnrp+kLscaOWc6whcBTxsZntWvcg5N805F3POxcrKyuo4pB2orPSn6bz4YjTWs6dfk9+i6u84ESlqp5/ul2+3aRONlZf7lT5ffhkurjSkk/SXAfsn9VvGx7Z7jZnVA5oCK51zG5xzKwGcc3OAj4CDaxt0RjnniyudcAJ88kk0PmoUPPEE7L57uNhEJHe1b+9nAZI3cT39tD8L+803w8VVjXSS/mygnZm1MbNSoBcws8o1M4FL4u1zgb8455yZlcUfBGNmbYF2wOLMhJ4Bq1b5QxMGDIANG/xY06b+8JMxY3TilYjsXPPmfoHHsGHR2JIlftXf+PE5Od1TbVaLz9EPAGYBC4AZzrn5ZlZuZt3jl90H7G1mi/DTOIllnScC75rZXPwD3r7OuVWZ/p/YJS+84E/OeeqpaOyII/w0T/JmDBGRnalXzyf4J57wN43gF4QMH+6ngZJnEHKAuRyrJRGLxVxl8s7XTPvqKxg6FO68M3V84EC4+WZo2LDu/m4RKWxLlsAFF6SWa9lzT1+U8bLL/AqgOmJmc5xzsequK675i+eeg8MPT034e+/tp3NuvVUJX0Rqp3Vrv7x7xIgowa9ZA717+6MZlywJGR1QLEn/s8/8b98zzoiONQS/Omf+fE3niEjm1K/va/C/9hq0axeNP/usf/g7YQJs2hQsvMJO+ps2+Tv4734XHnkkGv/Wt+CBB3z51H33DRefiBSuH/zA79YdNCi661+/3j/0/f73U5eHZ1HhJv2nn4bDDvOlUBOlFMDf8X/wAVx0UZ3Or4mI0LgxTJ0Kr7/up5YT3nvPl2rv2RM+/DCrIRVe0n/zTb9utls3WLgwGj/oID+n/9BDursXkew69li/MnDCBP+LIOEPf4Dvfc8fyr58eVZCKZykP28e9OgBxx0Hf/lLNL7nnv6A4/feg9NOCxefiBS3+vVhyBBfpj35PO1Nm3wxtwMP9FM/q+p2VXthJP0PPvBr7Gcm7RkrKYE+ffxHp6uv9nWxRURCa9ECfvc7v5u3c1I5svXr/SeBH/ygTjd1FUbS/+53U+/izz8fFiyAu++GffYJF5eIyI4cfbRf3vnMM6kFHa+8sk6rAdSrsz8528aN83fzY8f6u34RkVxn5iv7nn66X0147711fkhT8e3IFREpQNqRKyIi21DSFxEpIkr6IiJFRElfRKSIKOmLiBQRJX0RkSKipC8iUkRybp2+ma0APg4dRxXNgS9CB5ED9H3Q9wD0PUjIte/DAc65suouyrmkn4vMrDKdTQ+FTt8HfQ9A34OEfP0+aHpHRKSIKOmLiBQRJf30TAsdQI7Q90HfA9D3ICEvvw+a0xcRKSK60xcRKSJK+mkys4lm9oGZvWtmvzezb4WOKdvM7Dwzm29mW80s71Yt1IaZdTGzhWa2yMyuCR1PCGb2azP73MzeCx1LKGa2v5m9ZGbvx/8tDAodU00p6afveaCDc+5w4J/A8MDxhPAecA7w19CBZJOZlQAVQFegPXC+mbUPG1UQvwW6hA4isM3AYOdce+BYoH++/Swo6afJOfecc25zvPsm0DJkPCE45xY45xaGjiOATsAi59xi59xGYDrQI3BMWeec+ytQt6d25zjn3HLn3Nvx9lpgAdAibFQ1o6S/a34OPBM6CMmaFsCnSf2l5Nk/dMk8M2sNdAT+HjaSmimcM3IzwMxeAL69nZdGOuf+EL9mJP4j3kPZjC1b0vkeiBQ7M2sCPAH8wjm3JnQ8NaGkn8Q5d+rOXjezS4GzgFNcga51re57UKSWAfsn9VvGx6QImVl9fMJ/yDn3ZOh4akrTO2kysy7AUKC7c25d6Hgkq2YD7cysjZmVAr2AmYFjkgDMzID7gAXOucmh49kVSvrpux3YA3jezOaa2V2hA8o2M/uxmS0FjgP+bGazQseUDfEH+AOAWfgHdzOcc/PDRpV9ZvYI8AZwiJktNbPeoWMK4HjgYuBH8Tww18zODB1UTWhHrohIEdGdvohIEVHSFxEpIkr6IiJFRElfRKSIKOmLiBQRJX0RkSKipC8iUkSU9EVEisj/B/MUGlQZBNQWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = np.linspace(t.ppf(0.01, df),t.ppf(0.99, df), 100)\n",
    "plt.plot(x, t.pdf(x, df), 'r-', lw=3)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% (97.5%) of values are below 2.3289712732415597 1.9616324708209134\n",
      "\n",
      "t_val 3.348107823525538 is lower 99%; no rejection at alpha=1%, but higher 97.5% thus rejection at alpha=2.5%\n"
     ]
    }
   ],
   "source": [
    "# statistically significant difference between svm  perceptron??\n",
    "#\n",
    "# t-test (one-sided, subtract lower from higher, thus look at the right side of the normal distribution)\n",
    "\n",
    "# pairwise difference of svm and perceptron\n",
    "diff=np.array([tp_svm[i]-tp_perceptron[i] for i in range(0,len(y_test))])\n",
    "\n",
    "df=len(y_test)-1\n",
    "\n",
    "mean=np.mean(diff)\n",
    "std=np.std(diff,ddof=1)\n",
    "\n",
    "print(\"99% (97.5%) of values are below\", t.ppf(0.99,df-1),(t.ppf(0.975,df-1)))\n",
    "\n",
    "#diff = np.array(tp_svm)-np.array(tp_dec)\n",
    "\n",
    "t_val=mean/(std/np.sqrt(len(y_test)))\n",
    "\n",
    "print(\"\\nt_val\",t_val,\"is lower 99%; no rejection at alpha=1%, but higher 97.5% thus rejection at alpha=2.5%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additional neut\t 0.8935969868173258\n",
      "original neut\t 0.9157894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf4 = svm.SVC(kernel='rbf', random_state=0, gamma=0.10, C=10.0)\n",
    "\n",
    "clf4.fit(X_train,y_train)\n",
    "\n",
    "#precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None)\n",
    "\n",
    "y_test_predict_neut=clf4.predict(X_test_neut)\n",
    "print(\"additional neut\\t\",accuracy_score(y_test_neut,y_test_predict_neut))\n",
    "y_test_predict=clf4.predict(X_test)\n",
    "print(\"original neut\\t\", accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92875318 0.86425339 0.88832487] [0.94072165 0.86036036 0.85365854] [0.9346991  0.86230248 0.87064677]\n",
      "additional neut\t 0.885593220338983\n",
      "original neut\t 0.9031578947368422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation='relu',\n",
    "                    hidden_layer_sizes=(300,10), random_state=1,validation_fraction=0.2,early_stopping=False)\n",
    "                  \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None))\n",
    "\n",
    "y_test_predict_neut=clf.predict(X_test_neut)\n",
    "print(\"additional neut\\t\",accuracy_score(y_test_neut,y_test_predict_neut))\n",
    "y_test_predict=clf.predict(X_test)\n",
    "print(\"original neut\\t\", accuracy_score(y_test,y_test_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55035461 0.8        0.8       ] [1.         0.01801802 0.0195122 ] [0.70997255 0.03524229 0.03809524]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5529824561403509"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "#sgd=SGDClassifier(random_state=42, max_iter=5)\n",
    "sgd=SGDClassifier(random_state=42,loss='log', alpha=0.01,max_iter=5)\n",
    "\n",
    "sgd.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=sgd.predict(X_test)\n",
    "\n",
    "print(precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None))\n",
    "accuracy_score(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 20}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search the hyperparameter of a ML approach for the optimal combination\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    loss= ['hinge', 'log', 'modified_huber','squared_hinge', 'perceptron']\n",
    "    alpha=[0.5,0.1,0.01,0.001,0.0001]\n",
    "    maxiter=[1,4,5,10,11,12,15,20]\n",
    "    param_grid = {'loss': loss,'alpha':alpha,'max_iter':maxiter}\n",
    "    grid_search = GridSearchCV(sgd, param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "p=svc_param_selection(X_train,y_train,5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171929824561403"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd=SGDClassifier(random_state=42,loss='hinge', alpha=0.0001,max_iter=20)\n",
    "\n",
    "sgd.fit(X_train,y_train)\n",
    "\n",
    "y_test_predict=sgd.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    activation= ['tanh','relu']\n",
    "    alpha=[0.5,0.1,0.01,0.001,0.0001]\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    "    early_stopping=[False,True]\n",
    "    param_grid = {'activation': activation,'alpha':alpha,'solver':solver,'early_stopping':early_stopping}\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "p=svc_param_selection(X_train,y_train,5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    hidden_layer_sizes=[(200,10),(300,10),(200,50),(300,100),(200,100)]\n",
    "    activation= ['relu']\n",
    "    solver=['adam']\n",
    "    alpha=[0.1]\n",
    "    early_stopping=[True]\n",
    "    param_grid = {'hidden_layer_sizes':hidden_layer_sizes,'activation': activation,'alpha':alpha,'solver':solver,'early_stopping':early_stopping}\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "p=svc_param_selection(X_train,y_train,5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92546584 0.89411765 0.93333333] [0.96005155 0.85585586 0.88780488] [0.94244149 0.87456847 0.91      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9171929824561403"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimized settings\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, activation='relu',\n",
    "                    hidden_layer_sizes=(300,10), random_state=1,validation_fraction=0.2,early_stopping=True)\n",
    "                  \n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict=clf.predict(X_test)\n",
    "\n",
    "print(precision_score(y_test,y_test_predict,average=None), recall_score(y_test,y_test_predict,average=None), f1_score(y_test,y_test_predict,average=None))\n",
    "\n",
    "accuracy_score(y_test,y_test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
